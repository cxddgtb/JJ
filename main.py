import os
import datetime
import time
import json
import re
import concurrent.futures
import traceback
import google.generativeai as genai
import requests
import pandas as pd
import yfinance as yf
from bs4 import BeautifulSoup
from ddgs import DDGS

# --- å…¨å±€é…ç½® ---
HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36'}
TIMESTAMP_FILE, MIN_INTERVAL_HOURS, REQUESTS_TIMEOUT = "last_run_timestamp.txt", 6, 30

# --- åŸºç¡€è¾…åŠ©å‡½æ•° ---
def load_config():
    with open('config.json', 'r', encoding='utf-8') as f: config = json.load(f)
    config.setdefault('historical_days_to_display', 7)
    return config

def check_time_interval():
    if os.getenv('GITHUB_EVENT_NAME') != 'repository_dispatch' or not os.path.exists(TIMESTAMP_FILE): return True
    with open(TIMESTAMP_FILE, "r") as f: last_run_timestamp = float(f.read())
    if (time.time() - last_run_timestamp) / 3600 < MIN_INTERVAL_HOURS: return False
    return True

def update_timestamp():
    with open(TIMESTAMP_FILE, "w") as f: f.write(str(time.time()))

# --- æ•°æ®è·å–æ¨¡å— (yfinanceæ ¸å¿ƒ) ---
def get_fund_data_from_yfinance(fund_code, history_days, ma_days):
    """
    ç»ˆææ–¹æ¡ˆ: ä½¿ç”¨yfinanceè·å–åŸºé‡‘å†å²æ•°æ®ã€‚
    è‡ªåŠ¨å°è¯• .SS (ä¸Šæµ·) å’Œ .SZ (æ·±åœ³) åç¼€ã€‚
    """
    print(f"    YFINANCE: æ­£åœ¨ä¸º {fund_code} å¯åŠ¨é›…è™è´¢ç»æ•°æ®æ ¸å¿ƒ...")
    
    tickers_to_try = [f"{fund_code}.SS", f"{fund_code}.SZ"]
    hist_df = None
    
    for ticker in tickers_to_try:
        try:
            fund = yf.Ticker(ticker)
            # è·å–æ¯”è®¡ç®—å‡çº¿æ‰€éœ€å¤©æ•°æ›´å¤šçš„æ•°æ®ï¼Œä»¥ç¡®ä¿å‡çº¿å‡†ç¡®
            hist_df = fund.history(period=f"{history_days + ma_days}d")
            if not hist_df.empty:
                print(f"    YFINANCE: âœ… æˆåŠŸä½¿ç”¨ä»£ç  {ticker} è·å–åˆ°æ•°æ®ã€‚")
                break # æˆåŠŸè·å–ï¼Œè·³å‡ºå¾ªç¯
        except Exception:
            # yfinanceåœ¨æ‰¾ä¸åˆ°tickeræ—¶å¯èƒ½ä¼šæ‰“å°é”™è¯¯ï¼Œæˆ‘ä»¬å¿½ç•¥å®ƒå¹¶ç»§ç»­
            continue
            
    if hist_df is None or hist_df.empty:
        raise ValueError(f"æ— æ³•åœ¨é›…è™è´¢ç»æ‰¾åˆ°ä»£ç ä¸º {fund_code} çš„åŸºé‡‘æ•°æ®(.SS/.SZå‡å°è¯•å¤±è´¥)ã€‚")
        
    # --- æ•°æ®å¤„ç† ---
    # yfinanceè¿”å›çš„æ•°æ®åˆ—åæ˜¯å¤§å†™çš„
    hist_df.rename(columns={'Open': 'å¼€ç›˜', 'High': 'æœ€é«˜', 'Low': 'æœ€ä½', 'Close': 'æ”¶ç›˜', 'Volume': 'æˆäº¤é‡'}, inplace=True)
    
    # è®¡ç®—æ—¥å¢é•¿ç‡
    hist_df['æ—¥å¢é•¿ç‡'] = hist_df['æ”¶ç›˜'].pct_change() * 100
    
    # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
    hist_df[f'MA{ma_days}'] = hist_df['æ”¶ç›˜'].rolling(window=ma_days).mean()
    
    # è·å–åŸºé‡‘åç§°
    try:
        fund_name = fund.info.get('longName', fund_code)
    except Exception:
        fund_name = fund_code # å¦‚æœè·å–åç§°å¤±è´¥ï¼Œåˆ™ä½¿ç”¨ä»£ç 

    return fund_name, hist_df.tail(history_days) # åªè¿”å›éœ€è¦çš„å†å²å¤©æ•°

# --- æ•°æ®å¤„ç†ä¸æŠ¥å‘Šç”Ÿæˆ ---
def process_fund_data(fund_name, hist_df, fund_code, ma_days, days_to_display):
    try:
        print(f"æ­£åœ¨å¤„ç†åŸºé‡‘ {fund_code} çš„æ•°æ®...")
        latest_data = hist_df.iloc[-1]
        
        structured_data = {
            'name': fund_name, 'code': fund_code,
            'latest_price': latest_data['æ”¶ç›˜'],
            'latest_ma': latest_data[f'MA{ma_days}'],
            'daily_growth': latest_data['æ—¥å¢é•¿ç‡'],
            'ma_days': ma_days
        }
        
        recent_df = hist_df.tail(days_to_display).sort_index(ascending=False)
        table_rows = []
        for index, row in recent_df.iterrows():
            ma_val = row[f'MA{ma_days}']
            ma_str = f"{ma_val:.4f}" if not pd.isna(ma_val) else "N/A"
            trend_emoji = "ğŸ“ˆ" if row['æ”¶ç›˜'] > ma_val else "ğŸ“‰" if not pd.isna(ma_val) else "ğŸ¤”"
            table_rows.append(f"| {index.strftime('%Y-%m-%d')} | {row['æ”¶ç›˜']:.4f}   | {ma_str}    | {trend_emoji}  |")

        formatted_string = f"""
### åŸºé‡‘: {fund_name} ({fund_code})
- **æœ€æ–°å‡€å€¼**: {latest_data['æ”¶ç›˜']:.4f} (æˆªè‡³: {latest_data.name.strftime('%Y-%m-%d')})
- **{ma_days}æ—¥å‡çº¿**: {latest_data[f'MA{ma_days}']:.4f if not pd.isna(latest_data[f'MA{ma_days}']) else 'æ•°æ®ä¸è¶³'}
- **æŠ€æœ¯åˆ†æ**: å½“å‰å‡€å€¼åœ¨ {ma_days}æ—¥å‡çº¿**{'ä¹‹ä¸Š' if latest_data['æ”¶ç›˜'] > latest_data[f'MA{ma_days}'] else 'ä¹‹ä¸‹'}**ã€‚
- **æœ€è¿‘ {days_to_display} æ—¥è¯¦ç»†æ•°æ®**:
| æ—¥æœŸ       | å•ä½å‡€å€¼ | {ma_days}æ—¥å‡çº¿ | è¶‹åŠ¿ |
|:-----------|:---------|:------------|:-----|
""" + "\n".join(table_rows)
        return structured_data, formatted_string
    except Exception as e:
        print(f"âŒ å¤„ç†åŸºé‡‘ {fund_code} æ•°æ®æ—¶å‡ºé”™: {e}"); traceback.print_exc()
        return None, None

# ... [search_news, get_sector_data, generate_rule_based_report, AI report, call_gemini_ai ç­‰å‡½æ•°ä¿æŒå’Œä¹‹å‰ç‰ˆæœ¬ä¸€è‡´] ...
def search_news(keyword):
    print(f"æ­£åœ¨æœç´¢æ–°é—»: {keyword}...")
    try:
        with DDGS() as ddgs:
            return "\n".join([f"- [æ ‡é¢˜] {r['title']}\n  [æ‘˜è¦] {r.get('body', 'æ— ')}\n" for r in ddgs.news(keyword, region='cn-zh', safesearch='off', max_results=5)])
    except Exception as e: return f"æœç´¢å…³é”®è¯ '{keyword}' å¤±è´¥: {e}"
def get_sector_data():
    print("æ­£åœ¨çˆ¬å–è¡Œä¸šæ¿å—æ•°æ®...")
    try:
        response = requests.get("http://quote.eastmoney.com/center/boardlist.html#industry_board", headers=HEADERS, timeout=REQUESTS_TIMEOUT)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        sectors = [{'name': cols[1].find('a').text.strip(), 'change': float(cols[4].text.strip().replace('%', ''))} for row in soup.select('table#table_wrapper-table tbody tr') if len(cols := row.find_all('td')) > 5]
        sectors.sort(key=lambda x: x['change'], reverse=True)
        rising_str = "\n".join([f"  - {s['name']}: {s['change']:.2f}%" for s in sectors[:10]])
        falling_str = "\n".join([f"  - {s['name']}: {s['change']:.2f}%" for s in sectors[-10:]])
        return f"**ã€çƒ­é—¨ä¸Šæ¶¨æ¿å—ã€‘**\n{rising_str}\n\n**ã€çƒ­é—¨ä¸‹è·Œæ¿å—ã€‘**\n{falling_str}"
    except Exception as e:
        print(f"âŒ è¡Œä¸šæ¿å—æ•°æ®çˆ¬å–å¤±è´¥: {e}"); return "è¡Œä¸šæ¿å—æ•°æ®çˆ¬å–å¤±è´¥ã€‚"
def generate_rule_based_report(fund_datas, beijing_time):
    print("æ­£åœ¨ç”Ÿæˆâ€œè§„åˆ™å¤§è„‘â€åˆ†ææŠ¥å‘Š...")
    report_parts = [f"# åŸºé‡‘é‡åŒ–è§„åˆ™åˆ†ææŠ¥å‘Š ({beijing_time.strftime('%Y-%m-%d')})\n", "æœ¬æŠ¥å‘Šç”±é¢„è®¾é‡åŒ–è§„åˆ™ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒã€‚\n"]
    if not fund_datas:
        report_parts.append("### **æ³¨æ„ï¼šæœªèƒ½ä»é›…è™è´¢ç»è·å–ä»»ä½•åŸºé‡‘æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆåˆ†æã€‚**")
    else:
        for data in fund_datas:
            score, reasons = 0, []
            if not pd.isna(data['latest_ma']):
                if data['latest_price'] > data['latest_ma']: score += 2; reasons.append(f"å‡€å€¼({data['latest_price']:.4f})åœ¨{data['ma_days']}æ—¥å‡çº¿({data['latest_ma']:.4f})ä¹‹ä¸Š")
                else: score -= 2; reasons.append(f"å‡€å€¼({data['latest_price']:.4f})åœ¨{data['ma_days']}æ—¥å‡çº¿({data['latest_ma']:.4f})ä¹‹ä¸‹")
            if data['daily_growth'] > 0: score += 1; reasons.append(f"å½“æ—¥ä¸Šæ¶¨({data['daily_growth']:.2f}%)")
            else: score -= 1; reasons.append(f"å½“æ—¥ä¸‹è·Œ({data['daily_growth']:.2f}%)")
            if score == 3: conclusion = "å¼ºçƒˆçœ‹å¥½ ğŸš€"
            elif score == 1: conclusion = "è°¨æ…ä¹è§‚ ğŸ‘"
            elif score == -1: conclusion = "æ³¨æ„é£é™© âš ï¸"
            else: conclusion = "å»ºè®®å‡ä»“ ğŸ“‰"
            report_parts.append(f"### {data['name']} ({data['code']})\n- **é‡åŒ–è¯„åˆ†**: {score}\n- **ç»¼åˆç»“è®º**: {conclusion}\n- **è¯„åˆ†ä¾æ®**: {', '.join(reasons)}\n")
    report_parts.append("\n---\n**å…è´£å£°æ˜**: æœ¬æŠ¥å‘Šç”±è‡ªåŠ¨åŒ–è§„åˆ™ç”Ÿæˆï¼Œä¸æ„æˆä»»ä½•æŠ•èµ„å»ºè®®ã€‚")
    return "\n".join(report_parts)
def call_gemini_ai(prompt):
    try:
        genai.configure(api_key=os.environ.get("GEMINI_API_KEY"))
        model = genai.GenerativeModel("gemini-1.5-flash")
        response = model.generate_content(prompt, request_options={'timeout': 180})
        return response.text
    except Exception as e:
        print(f"âŒ è°ƒç”¨ Gemini AI å¤±è´¥: {e}"); traceback.print_exc()
        return "AIæ¨¡å‹è°ƒç”¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥æˆ–ç½‘ç»œè¿æ¥ã€‚"
def generate_ai_based_report(news, sectors, funds_string):
    print("æ­£åœ¨è¯·æ±‚â€œAIç­–ç•¥å¤§è„‘â€ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
    if not funds_string.strip():
        return "ç”±äºæœªèƒ½è·å–ä»»ä½•åŸºé‡‘çš„è¯¦ç»†æ•°æ®ï¼ŒAIç­–ç•¥å¤§è„‘æ— æ³•è¿›è¡Œåˆ†æã€‚"
    analysis_prompt = f"ä½œä¸ºä¸€åæ•°æ®é©±åŠ¨çš„é‡åŒ–æŠ•èµ„ç­–ç•¥å¸ˆ...[çœç•¥è¯¦ç»†æŒ‡ä»¤]...\n**ç¬¬ä¸€éƒ¨åˆ†ï¼šå®è§‚æ–°é—»**\n{news}\n**ç¬¬äºŒéƒ¨åˆ†ï¼šæ¿å—è½®åŠ¨**\n{sectors}\n**ç¬¬ä¸‰éƒ¨åˆ†ï¼šæŒä»“åŸºé‡‘è¯¦ç»†æ•°æ®**\n{funds_string}"
    draft_article = call_gemini_ai(analysis_prompt)
    if "AIæ¨¡å‹è°ƒç”¨å¤±è´¥" in draft_article: return draft_article
    polish_prompt = f"ä½œä¸ºä¸€åå–„äºç”¨æ•°æ®è¯´è¯çš„æŠ•èµ„ç¤¾åŒºKOL...[çœç•¥è¯¦ç»†æŒ‡ä»¤]...\n**ã€åŸå§‹æŠ¥å‘Šã€‘**\n{draft_article}"
    return call_gemini_ai(polish_prompt)
    
def main():
    if not check_time_interval(): return
    config = load_config()
    beijing_time = datetime.datetime.utcnow() + datetime.timedelta(hours=8)
    
    structured_fund_datas, formatted_fund_strings = [], []
    print("å¼€å§‹å¹¶è¡Œè·å–æ‰€æœ‰åŸºé‡‘æ•°æ®...")
    with concurrent.futures.ThreadPoolExecutor(max_workers=len(config['fund_codes'])) as executor:
        future_to_code = {executor.submit(get_fund_data_from_yfinance, code, config['historical_days_to_fetch'], config['moving_average_days']): code for code in config['fund_codes']}
        for future in concurrent.futures.as_completed(future_to_code):
            code = future_to_code[future]
            try:
                fund_name, hist_df = future.result()
                structured, formatted = process_fund_data(fund_name, hist_df, code, config['moving_average_days'], config['historical_days_to_display'])
                if structured and formatted:
                    structured_fund_datas.append(structured)
                    formatted_fund_strings.append(formatted)
            except Exception as e:
                print(f"è·å–å¹¶å¤„ç†åŸºé‡‘ {code} æ•°æ®æ—¶å‘ç”Ÿé¡¶å±‚é”™è¯¯: {e}")

    all_news_text = "\n".join([search_news(kw) for kw in config['news_keywords']])
    sector_data_text = get_sector_data()

    if not os.path.exists('reports'): os.makedirs('reports')
    
    rule_report = generate_rule_based_report(structured_fund_datas, beijing_time)
    rule_filename = f"reports/åŸºé‡‘åˆ†ææŠ¥å‘Š-è§„åˆ™ç‰ˆ_{beijing_time.strftime('%Y-%m-%d_%H-%M')}.md"
    with open(rule_filename, 'w', encoding='utf-8') as f: f.write(rule_report)
    print(f"\nâœ… â€œè§„åˆ™å¤§è„‘â€æŠ¥å‘Šå·²æˆåŠŸä¿å­˜ä¸º: {rule_filename}")

    ai_report = generate_ai_based_report(all_news_text, sector_data_text, "\n".join(formatted_fund_strings))
    ai_filename = f"reports/åŸºé‡‘åˆ†ææŠ¥å‘Š-AIç‰ˆ_{beijing_time.strftime('%Y-%m-%d_%H-%M')}.md"
    with open(ai_filename, 'w', encoding='utf-8') as f: f.write(ai_report)
    print(f"âœ… â€œAIç­–ç•¥å¤§è„‘â€æŠ¥å‘Šå·²æˆåŠŸä¿å­˜ä¸º: {ai_filename}")

    update_timestamp()

if __name__ == "__main__":
    main()
