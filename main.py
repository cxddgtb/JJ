import os
import datetime
import time
import json
import concurrent.futures
import traceback
import google.generativeai as genai
import requests
import pandas as pd
import yfinance as yf
from bs4 import BeautifulSoup
from ddgs import DDGS
import re

# --- å…¨å±€é…ç½® ---
HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36'}
TIMESTAMP_FILE, MIN_INTERVAL_HOURS = "last_run_timestamp.txt", 6

# --- åŸºç¡€è¾…åŠ©å‡½æ•° ---
def load_config():
    with open('config.json', 'r', encoding='utf-8') as f: config = json.load(f)
    config.setdefault('historical_days_to_display', 7)
    return config

def check_time_interval():
    if os.getenv('GITHUB_EVENT_NAME') != 'repository_dispatch' or not os.path.exists(TIMESTAMP_FILE): return True
    with open(TIMESTAMP_FILE, "r") as f: last_run_timestamp = float(f.read())
    if (time.time() - last_run_timestamp) / 3600 < MIN_INTERVAL_HOURS: return False
    return True

def update_timestamp():
    with open(TIMESTAMP_FILE, "w") as f: f.write(str(time.time()))

# --- æ•°æ®è·å–æ¨¡å— (â€œåŒä¿é™©â€æ ¸å¿ƒ) ---
def get_fund_data_from_yfinance(fund_code, history_days):
    """ç¬¬ä¸€ä¿é™©: å°è¯•ä»yfinanceè·å–æ·±åº¦å†å²æ•°æ®"""
    print(f"    YFINANCE: æ­£åœ¨ä¸º {fund_code} å¯åŠ¨é›…è™è´¢ç»æ•°æ®æ ¸å¿ƒ...")
    tickers_to_try = [f"{fund_code}.SS", f"{fund_code}.SZ"]
    for ticker in tickers_to_try:
        try:
            hist_df = yf.Ticker(ticker).history(period=f"{history_days}d", auto_adjust=True)
            if not hist_df.empty:
                print(f"    YFINANCE: âœ… æˆåŠŸä½¿ç”¨ä»£ç  {ticker} è·å–åˆ°æ•°æ®ã€‚")
                fund_name = yf.Ticker(ticker).info.get('longName', fund_code)
                return {'type': 'history', 'name': fund_name, 'data': hist_df}
        except Exception: continue
    return None

def get_fund_data_from_search(fund_code):
    """ç¬¬äºŒä¿é™©: å¦‚æœyfinanceå¤±è´¥ï¼Œä»æœç´¢å¼•æ“è·å–å½“æ—¥å¿«ç…§"""
    print(f"    SEARCH_ENGINE: yfinanceå¤±è´¥, ä¸º {fund_code} å¯åŠ¨æœç´¢å¼•æ“å¤‡ç”¨æ–¹æ¡ˆ...")
    queries = [f"{fund_code} åŸºé‡‘å‡€å€¼", f"åŸºé‡‘ {fund_code} æœ€æ–°å‡€å€¼"]
    with DDGS(timeout=20) as ddgs:
        for query in queries:
            try:
                results = list(ddgs.text(query, region='cn-zh', max_results=2))
                for result in results:
                    snippet, title = result.get('body', ''), result.get('title', '')
                    match = re.search(r'(\d{4}[å¹´-]\d{2}[æœˆ-]\d{2}æ—¥?).*?å•ä½å‡€å€¼.*?(\d+\.\d+).*?(?:æ—¥å¢é•¿ç‡|æ¶¨è·Œå¹…).*?(-?\d+\.\d+)%', snippet)
                    if match:
                        fsrq, dwjz, jzzzl = match.groups()
                        fsrq_formatted = re.sub(r'[å¹´æœˆæ—¥]', '-', fsrq).strip('-')
                        fund_name = re.search(r'(.*?)\(', title).group(1).strip() if re.search(r'(.*?)\(', title) else fund_code
                        print(f"    SEARCH_ENGINE: âœ… æˆåŠŸä»æœç´¢ç»“æœè§£æ {fund_code} æ•°æ®ã€‚")
                        return {'type': 'snapshot', 'name': fund_name, 'date': fsrq_formatted, 'price': dwjz, 'growth': jzzzl}
            except Exception as e: print(f"      -> æŸ¥è¯¢ '{query}' æ—¶å‡ºç°ä¸´æ—¶é”™è¯¯: {e}")
    raise ValueError("æ‰€æœ‰æœç´¢å¼•æ“æŸ¥è¯¢å‡æœªèƒ½æˆåŠŸè§£æå‡€å€¼ã€‚")

def get_fund_data_robust(fund_code, history_days):
    """â€œåŒä¿é™©â€è°ƒåº¦å™¨"""
    result = get_fund_data_from_yfinance(fund_code, history_days)
    if result:
        return result
    return get_fund_data_from_search(fund_code)

# --- æ•°æ®å¤„ç†ä¸æŠ¥å‘Šç”Ÿæˆ (ç»ˆæä¿®å¤) ---
def process_fund_data(result, fund_code, ma_days, days_to_display):
    try:
        if result['type'] == 'history':
            print(f"æ­£åœ¨å¤„ç†åŸºé‡‘ {fund_code} çš„å†å²æ•°æ®...")
            fund_name, hist_df = result['name'], result['data']
            hist_df.rename(columns={'Close': 'æ”¶ç›˜'}, inplace=True)
            hist_df['æ”¶ç›˜'] = pd.to_numeric(hist_df['æ”¶ç›˜'], errors='coerce')
            hist_df.dropna(subset=['æ”¶ç›˜'], inplace=True)
            hist_df['æ—¥å¢é•¿ç‡'] = hist_df['æ”¶ç›˜'].pct_change() * 100
            hist_df[f'MA{ma_days}'] = hist_df['æ”¶ç›˜'].rolling(window=ma_days).mean()
            latest_data = hist_df.iloc[-1]
            structured = {'name': fund_name, 'code': fund_code, 'latest_price': latest_data['æ”¶ç›˜'], 'latest_ma': latest_data[f'MA{ma_days}'], 'daily_growth': latest_data['æ—¥å¢é•¿ç‡'], 'ma_days': ma_days}
            recent_df = hist_df.tail(days_to_display).sort_index(ascending=False)
            table_rows = [f"| {idx.strftime('%Y-%m-%d')} | {row['æ”¶ç›˜']:.4f} | {row[f'MA{ma_days}']:.4f if not pd.isna(row[f'MA{ma_days}']) else 'N/A'} | {'ğŸ“ˆ' if row['æ”¶ç›˜'] > row[f'MA{ma_days}'] else 'ğŸ“‰' if not pd.isna(row[f'MA{ma_days}']) else 'ğŸ¤”'} |" for idx, row in recent_df.iterrows()]
            formatted = f"### åŸºé‡‘: {fund_name} ({fund_code})\n- **æ•°æ®æ¥æº**: é›…è™è´¢ç» (æ·±åº¦å†å²)\n- **æœ€æ–°å‡€å€¼**: {latest_data['æ”¶ç›˜']:.4f} (æˆªè‡³: {latest_data.name.strftime('%Y-%m-%d')})\n- **{ma_days}æ—¥å‡çº¿**: {latest_data[f'MA{ma_days}']:.4f if not pd.isna(latest_data[f'MA{ma_days}']) else 'æ•°æ®ä¸è¶³'}\n- **æœ€è¿‘ {days_to_display} æ—¥è¯¦ç»†æ•°æ®**:\n| æ—¥æœŸ | å•ä½å‡€å€¼ | {ma_days}æ—¥å‡çº¿ | è¶‹åŠ¿ |\n|:---|:---|:---|:---|\n" + "\n".join(table_rows)
            return structured, formatted
        
        elif result['type'] == 'snapshot':
            print(f"æ­£åœ¨å¤„ç†åŸºé‡‘ {fund_code} çš„å½“æ—¥å¿«ç…§...")
            fund_name = result['name']
            structured = {'name': fund_name, 'code': fund_code, 'latest_price': float(result['price']), 'latest_ma': float('nan'), 'daily_growth': float(result['growth']), 'ma_days': ma_days}
            formatted = f"### åŸºé‡‘: {fund_name} ({fund_code})\n- **æ•°æ®æ¥æº**: æœç´¢å¼•æ“ (å½“æ—¥å¿«ç…§)\n- **æœ€æ–°å‡€å€¼**: {result['price']} (æˆªè‡³: {result['date']})\n- **æ—¥æ¶¨è·Œå¹…**: {result['growth']}%\n- **å¤‡æ³¨**: æœªèƒ½è·å–å®Œæ•´çš„å†å²æ•°æ®ï¼Œæ— æ³•è®¡ç®—ç§»åŠ¨å‡çº¿ã€‚"
            return structured, formatted
            
    except Exception as e:
        print(f"âŒ å¤„ç†åŸºé‡‘ {fund_code} æ•°æ®æ—¶å‡ºé”™: {e}"); traceback.print_exc()
        return None, None

# ... [å…¶ä»–è¾…åŠ©å‡½æ•° search_news, get_sector_data, reports, call_gemini_ai ç­‰ä¿æŒä¸å˜] ...
def search_news(keyword):
    print(f"æ­£åœ¨æœç´¢æ–°é—»: {keyword}...")
    with DDGS() as ddgs: return "\n".join([f"- [æ ‡é¢˜] {r['title']}\n  [æ‘˜è¦] {r.get('body', 'æ— ')}\n" for r in ddgs.news(keyword, region='cn-zh', max_results=5)])
def get_sector_data():
    print("æ­£åœ¨çˆ¬å–è¡Œä¸šæ¿å—æ•°æ®...")
    try:
        response = requests.get("http://quote.eastmoney.com/center/boardlist.html#industry_board", headers=HEADERS, timeout=30)
        soup = BeautifulSoup(response.text, 'html.parser')
        sectors = [{'name': c[1].find('a').text.strip(), 'change': float(c[4].text.replace('%',''))} for r in soup.select('table#table_wrapper-table tbody tr') if len(c:=r.find_all('td'))>5]
        sectors.sort(key=lambda x: x['change'], reverse=True)
        rising = "\n".join([f"  - {s['name']}: {s['change']:.2f}%" for s in sectors[:10]])
        falling = "\n".join([f"  - {s['name']}: {s['change']:.2f}%" for s in sectors[-10:]])
        return f"**ã€çƒ­é—¨ä¸Šæ¶¨æ¿å—ã€‘**\n{rising}\n\n**ã€çƒ­é—¨ä¸‹è·Œæ¿å—ã€‘**\n{falling}"
    except Exception as e: return f"è¡Œä¸šæ¿å—æ•°æ®çˆ¬å–å¤±è´¥: {e}"
def generate_rule_based_report(fund_datas, beijing_time):
    report_parts = [f"# åŸºé‡‘é‡åŒ–è§„åˆ™åˆ†ææŠ¥å‘Š ({beijing_time.strftime('%Y-%m-%d')})\n"]
    if not fund_datas: report_parts.append("### **æ³¨æ„ï¼šæ‰€æœ‰æ•°æ®æºå‡æœªèƒ½è·å–ä»»ä½•åŸºé‡‘æ•°æ®ã€‚**")
    else:
        for data in fund_datas:
            score, reasons = 0, []
            if not pd.isna(data['latest_ma']):
                if data['latest_price'] > data['latest_ma']: score += 2; reasons.append("å‡€å€¼åœ¨å‡çº¿ä¹‹ä¸Š")
                else: score -= 2; reasons.append("å‡€å€¼åœ¨å‡çº¿ä¹‹ä¸‹")
            if not pd.isna(data['daily_growth']):
                if data['daily_growth'] > 0: score += 1; reasons.append("å½“æ—¥ä¸Šæ¶¨")
                else: score -= 1; reasons.append("å½“æ—¥ä¸‹è·Œ")
            
            if pd.isna(data['latest_ma']): # å¿«ç…§æ•°æ®çš„ç‰¹æ®Šåˆ¤æ–­
                conclusion = "è°¨æ…ä¹è§‚ ğŸ‘" if data['daily_growth'] > 0 else "æ³¨æ„é£é™© âš ï¸"
            elif score >= 2: conclusion = "å¼ºçƒˆçœ‹å¥½ ğŸš€"
            elif score >= 0: conclusion = "è°¨æ…ä¹è§‚ ğŸ‘"
            elif score > -2: conclusion = "æ³¨æ„é£é™© âš ï¸"
            else: conclusion = "å»ºè®®å‡ä»“ ğŸ“‰"
            report_parts.append(f"### {data['name']} ({data['code']})\n- **é‡åŒ–è¯„åˆ†**: {score if not pd.isna(data['latest_ma']) else 'N/A'}\n- **ç»¼åˆç»“è®º**: {conclusion}\n- **è¯„åˆ†ä¾æ®**: {', '.join(reasons)}\n")
    return "\n".join(report_parts)
def call_gemini_ai(prompt):
    try:
        genai.configure(api_key=os.environ.get("GEMINI_API_KEY"))
        return genai.GenerativeModel("gemini-1.5-flash").generate_content(prompt).text
    except Exception as e: return f"AIæ¨¡å‹è°ƒç”¨å¤±è´¥: {e}"
def generate_ai_based_report(news, sectors, funds_string):
    if not funds_string.strip(): return "ç”±äºæœªèƒ½è·å–ä»»ä½•åŸºé‡‘çš„è¯¦ç»†æ•°æ®ï¼ŒAIç­–ç•¥å¤§è„‘æ— æ³•è¿›è¡Œåˆ†æã€‚"
    analysis_prompt = f"""ä½œä¸ºä¸€åé¡¶çº§çš„ä¸­å›½å¸‚åœºå¯¹å†²åŸºé‡‘ç»ç†ï¼Œè¯·ç»“åˆä»¥ä¸‹æ‰€æœ‰ä¿¡æ¯ï¼Œæ’°å†™ä¸€ä»½åŒ…å«å®è§‚ã€ä¸­è§‚ã€å¾®è§‚ä¸‰ä¸ªå±‚æ¬¡çš„æ·±åº¦æŠ•ç ”æŠ¥å‘Šã€‚
**æ³¨æ„ï¼šéƒ¨åˆ†åŸºé‡‘å¯èƒ½åªæœ‰å½“æ—¥å¿«ç…§æ•°æ®ï¼Œç¼ºä¹å†å²å‡çº¿ï¼Œè¯·åœ¨åˆ†ææ—¶æ˜ç¡®æŒ‡å‡ºè¿™ä¸€ç‚¹ï¼Œå¹¶åšå‡ºæ›´è°¨æ…çš„åˆ¤æ–­ã€‚**
**ç¬¬ä¸€éƒ¨åˆ†ï¼šå¸‚åœºæ–°é—»ä¸æƒ…ç»ª**\n{news}\n**ç¬¬äºŒéƒ¨åˆ†ï¼šä¸­è§‚è¡Œä¸šä¸æ¿å—è½®åŠ¨**\n{sectors}\n**ç¬¬ä¸‰éƒ¨åˆ†ï¼šå¾®è§‚æŒä»“åŸºé‡‘æŠ€æœ¯çŠ¶æ€**\n{funds_string}"""
    draft = call_gemini_ai(analysis_prompt)
    if "AIæ¨¡å‹è°ƒç”¨å¤±è´¥" in draft: return draft
    polish_prompt = f"ä½œä¸ºä¸€åå–„äºç”¨æ•°æ®è®²æ•…äº‹çš„æŠ•èµ„KOL...[çœç•¥è¯¦ç»†æŒ‡ä»¤]...\n**ã€åŸå§‹æŠ¥å‘Šã€‘**\n{draft}"
    return call_gemini_ai(polish_prompt)
    
def main():
    if not check_time_interval(): return
    config, beijing_time = load_config(), datetime.datetime.utcnow() + datetime.timedelta(hours=8)
    structured_fund_datas, formatted_fund_strings, news_text, sector_text = [], [], "", ""

    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:
        future_funds = {executor.submit(get_fund_data_robust, c, config['historical_days_to_fetch']): c for c in config['fund_codes']}
        future_news = {executor.submit(search_news, kw): kw for kw in config['news_keywords']}
        future_sector = executor.submit(get_sector_data)

        for future in concurrent.futures.as_completed(future_funds):
            code = future_funds[future]
            try:
                result = future.result()
                if result:
                    structured, formatted = process_fund_data(result, code, config['moving_average_days'], config['historical_days_to_display'])
                    if structured: structured_fund_datas.append(structured); formatted_fund_strings.append(formatted)
            except Exception as e: print(f"è·å–å¹¶å¤„ç†åŸºé‡‘ {code} æ—¶å‘ç”Ÿé¡¶å±‚é”™è¯¯: {e}")
        
        news_text = "\n".join([f.result() for f in concurrent.futures.as_completed(future_news)])
        sector_text = future_sector.result()

    if not os.path.exists('reports'): os.makedirs('reports')
    
    rule_report = generate_rule_based_report(structured_fund_datas, beijing_time)
    with open(f"reports/åŸºé‡‘åˆ†ææŠ¥å‘Š-è§„åˆ™ç‰ˆ_{beijing_time.strftime('%Y-%m-%d')}.md", 'w', encoding='utf-8') as f: f.write(rule_report)
    print(f"\nâœ… â€œè§„åˆ™å¤§è„‘â€æŠ¥å‘Šå·²æˆåŠŸä¿å­˜ã€‚")

    ai_report = generate_ai_based_report(news_text, sector_text, "\n".join(formatted_fund_strings))
    with open(f"reports/åŸºé‡‘åˆ†ææŠ¥å‘Š-AIç‰ˆ_{beijing_time.strftime('%Y-%m-%d')}.md", 'w', encoding='utf-8') as f: f.write(ai_report)
    print(f"âœ… â€œAIç­–ç•¥å¤§è„‘â€æŠ¥å‘Šå·²æˆåŠŸä¿å­˜ã€‚")

    update_timestamp()

if __name__ == "__main__":
    main()
