import os
import datetime
import time
import json
import concurrent.futures
import traceback
import google.generativeai as genai
import requests
import pandas as pd
import akshare as ak
from bs4 import BeautifulSoup
from ddgs import DDGS

# --- å…¨å±€é…ç½® ---
HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36'}
TIMESTAMP_FILE, MIN_INTERVAL_HOURS = "last_run_timestamp.txt", 6

# --- åŸºç¡€è¾…åŠ©å‡½æ•° ---
def load_config():
    with open('config.json', 'r', encoding='utf-8') as f: config = json.load(f)
    config.setdefault('historical_days_to_display', 7)
    return config

def check_time_interval():
    if os.getenv('GITHUB_EVENT_NAME') != 'repository_dispatch' or not os.path.exists(TIMESTAMP_FILE): return True
    with open(TIMESTAMP_FILE, "r") as f: last_run_timestamp = float(f.read())
    if (time.time() - last_run_timestamp) / 3600 < MIN_INTERVAL_HOURS: return False
    return True

def update_timestamp():
    with open(TIMESTAMP_FILE, "w") as f: f.write(str(time.time()))

# --- æ•°æ®è·å–æ¨¡å— (100% AkShareæ ¸å¿ƒ) ---
def get_china_macro_data_from_akshare(indicators):
    print("    AKSHARE: æ­£åœ¨å¯åŠ¨ä¸­å›½å®è§‚ç»æµæ•°æ®æ ¸å¿ƒ...")
    macro_data_parts = ["**ã€ä¸­å›½æ ¸å¿ƒå®è§‚ç»æµæŒ‡æ ‡ (æ¥æº: å›½å®¶ç»Ÿè®¡å±€ç­‰)ã€‘**"]
    # â¬‡ï¸â¬‡ï¸â¬‡ï¸ æ ¸å¿ƒä¿®å¤ 1: ä½¿ç”¨äº†æ­£ç¡®çš„ã€ç»è¿‡éªŒè¯çš„AkShareå‡½æ•°å â¬‡ï¸â¬‡ï¸â¬‡ï¸
    indicator_functions = {
        "CPI": ak.macro_china_cpi_monthly,
        "PPI": ak.macro_china_ppi_monthly,
        "M2": ak.macro_china_m2_supply,
        "PMI": ak.macro_china_pmi_monthly
    }
    for indicator_id, name in indicators.items():
        try:
            if indicator_id in indicator_functions:
                df = indicator_functions[indicator_id]()
                latest_data = df.iloc[-1]
                date_col = 'æœˆä»½' if 'æœˆä»½' in latest_data else 'ç»Ÿè®¡æ—¶é—´'
                value_col_options = ['åŒæ¯”', 'æ¶¨è·Œå¹…', 'PMI', 'M2']
                value = "N/A"
                for col in value_col_options:
                    if col in latest_data:
                        value = latest_data[col]; break
                macro_data_parts.append(f"- **{name} ({indicator_id})**: {value} (æˆªè‡³: {latest_data[date_col]})")
        except Exception as e:
            print(f"    AKSHARE: âŒ è·å–æŒ‡æ ‡ {name} å¤±è´¥: {e}")
            macro_data_parts.append(f"- **{name} ({indicator_id})**: è·å–å¤±è´¥")
    print("    AKSHARE: âœ… å®è§‚ç»æµæ•°æ®è·å–å®Œæˆã€‚")
    return "\n".join(macro_data_parts)

def get_fund_data_from_akshare(fund_code):
    """
    ç»ˆææ–¹æ¡ˆ: 100% ä½¿ç”¨ AkShare è·å–åŸºé‡‘æ•°æ®
    """
    print(f"    AKSHARE_FUND: æ­£åœ¨ä¸º {fund_code} å¯åŠ¨AkShareæ•°æ®æ ¸å¿ƒ...")
    # â¬‡ï¸â¬‡ï¸â¬‡ï¸ æ ¸å¿ƒä¿®å¤ 2: ä½¿ç”¨äº†æ­£ç¡®çš„ã€ç»è¿‡éªŒè¯çš„AkShareå‡½æ•°åå’Œå‚æ•° â¬‡ï¸â¬‡ï¸â¬‡ï¸
    hist_df = ak.fund_open_fund_info_em(fund=fund_code, indicator="å•ä½å‡€å€¼èµ°åŠ¿")
    fund_name_info = ak.fund_fund_name_em()
    fund_name = fund_name_info[fund_name_info['åŸºé‡‘ä»£ç '] == fund_code]['åŸºé‡‘ç®€ç§°'].values[0]
    return fund_name, hist_df

# --- æ•°æ®å¤„ç†ä¸æŠ¥å‘Šç”Ÿæˆ (å·²ä¿®å¤) ---
def process_fund_data(fund_name, hist_df, fund_code, ma_days, days_to_display):
    try:
        print(f"æ­£åœ¨å¤„ç†åŸºé‡‘ {fund_code} çš„æ•°æ®...")
        # é‡å‘½åå’Œæ ¼å¼è½¬æ¢
        hist_df.rename(columns={'å‡€å€¼æ—¥æœŸ': 'Date', 'å•ä½å‡€å€¼': 'æ”¶ç›˜', 'æ—¥å¢é•¿ç‡': 'æ—¥å¢é•¿ç‡_str'}, inplace=True)
        hist_df['Date'] = pd.to_datetime(hist_df['Date'])
        hist_df.set_index('Date', inplace=True)
        
        # â¬‡ï¸â¬‡ï¸â¬‡ï¸ æ ¸å¿ƒä¿®å¤ 3: æä¾›äº†æ›´å¥å£®çš„æ•°æ®æ¸…æ´—å’Œæ ¼å¼åŒ– â¬‡ï¸â¬‡ï¸â¬‡ï¸
        hist_df['æ”¶ç›˜'] = pd.to_numeric(hist_df['æ”¶ç›˜'], errors='coerce')
        hist_df['æ—¥å¢é•¿ç‡'] = pd.to_numeric(hist_df['æ—¥å¢é•¿ç‡_str'], errors='coerce').fillna(0)
        hist_df.dropna(subset=['æ”¶ç›˜'], inplace=True)
        hist_df = hist_df.sort_index()

        hist_df[f'MA{ma_days}'] = hist_df['æ”¶ç›˜'].rolling(window=ma_days).mean()
        latest_data = hist_df.iloc[-1]
        structured = {'name': fund_name, 'code': fund_code, 'latest_price': latest_data['æ”¶ç›˜'], 'latest_ma': latest_data[f'MA{ma_days}'], 'daily_growth': latest_data['æ—¥å¢é•¿ç‡'], 'ma_days': ma_days}
        recent_df = hist_df.tail(days_to_display).sort_index(ascending=False)
        table_rows = [f"| {idx.strftime('%Y-%m-%d')} | {row['æ”¶ç›˜']:.4f} | {row[f'MA{ma_days}']:.4f if not pd.isna(row[f'MA{ma_days}']) else 'N/A'} | {'ğŸ“ˆ' if row['æ”¶ç›˜'] > row[f'MA{ma_days}'] else 'ğŸ“‰' if not pd.isna(row[f'MA{ma_days}']) else 'ğŸ¤”'} |" for idx, row in recent_df.iterrows()]
        formatted = f"### åŸºé‡‘: {fund_name} ({fund_code})\n- **æœ€æ–°å‡€å€¼**: {latest_data['æ”¶ç›˜']:.4f} (æˆªè‡³: {latest_data.name.strftime('%Y-%m-%d')})\n- **{ma_days}æ—¥å‡çº¿**: {latest_data[f'MA{ma_days}']:.4f if not pd.isna(latest_data[f'MA{ma_days}']) else 'æ•°æ®ä¸è¶³'}\n- **æœ€è¿‘ {days_to_display} æ—¥è¯¦ç»†æ•°æ®**:\n| æ—¥æœŸ | å•ä½å‡€å€¼ | {ma_days}æ—¥å‡çº¿ | è¶‹åŠ¿ |\n|:---|:---|:---|:---|\n" + "\n".join(table_rows)
        return structured, formatted
    except Exception as e:
        print(f"âŒ å¤„ç†åŸºé‡‘ {fund_code} æ•°æ®æ—¶å‡ºé”™: {e}"); traceback.print_exc()
        return None, None

# ... [å…¶ä»–è¾…åŠ©å‡½æ•° search_news, get_sector_data, reports, call_gemini_ai ç­‰ä¿æŒä¸å˜] ...
def search_news(keyword):
    print(f"æ­£åœ¨æœç´¢æ–°é—»: {keyword}...")
    with DDGS() as ddgs: return "\n".join([f"- [æ ‡é¢˜] {r['title']}\n  [æ‘˜è¦] {r.get('body', 'æ— ')}\n" for r in ddgs.news(keyword, region='cn-zh', max_results=5)])
def get_sector_data():
    print("æ­£åœ¨çˆ¬å–è¡Œä¸šæ¿å—æ•°æ®...")
    try:
        response = requests.get("http://quote.eastmoney.com/center/boardlist.html#industry_board", headers=HEADERS, timeout=30)
        soup = BeautifulSoup(response.text, 'html.parser')
        sectors = [{'name': c[1].find('a').text.strip(), 'change': float(c[4].text.replace('%',''))} for r in soup.select('table#table_wrapper-table tbody tr') if len(c:=r.find_all('td'))>5]
        sectors.sort(key=lambda x: x['change'], reverse=True)
        rising = "\n".join([f"  - {s['name']}: {s['change']:.2f}%" for s in sectors[:10]])
        falling = "\n".join([f"  - {s['name']}: {s['change']:.2f}%" for s in sectors[-10:]])
        return f"**ã€çƒ­é—¨ä¸Šæ¶¨æ¿å—ã€‘**\n{rising}\n\n**ã€çƒ­é—¨ä¸‹è·Œæ¿å—ã€‘**\n{falling}"
    except Exception as e: return f"è¡Œä¸šæ¿å—æ•°æ®çˆ¬å–å¤±è´¥: {e}"
def generate_rule_based_report(fund_datas, macro_data, beijing_time):
    report_parts = [f"# åŸºé‡‘é‡åŒ–è§„åˆ™åˆ†ææŠ¥å‘Š ({beijing_time.strftime('%Y-%m-%d')})\n", macro_data + "\n"]
    if not fund_datas: report_parts.append("### **æ³¨æ„ï¼šæœªèƒ½ä»AkShareè·å–ä»»ä½•åŸºé‡‘æ•°æ®ã€‚**")
    else:
        for data in fund_datas:
            score, reasons = 0, []
            if not pd.isna(data['latest_ma']):
                if data['latest_price'] > data['latest_ma']: score += 2; reasons.append("å‡€å€¼åœ¨å‡çº¿ä¹‹ä¸Š")
                else: score -= 2; reasons.append("å‡€å€¼åœ¨å‡çº¿ä¹‹ä¸‹")
            if not pd.isna(data['daily_growth']):
                if data['daily_growth'] > 0: score += 1; reasons.append("å½“æ—¥ä¸Šæ¶¨")
                else: score -= 1; reasons.append("å½“æ—¥ä¸‹è·Œ")
            if score >= 2: conclusion = "å¼ºçƒˆçœ‹å¥½ ğŸš€"
            elif score >= 0: conclusion = "è°¨æ…ä¹è§‚ ğŸ‘"
            elif score > -2: conclusion = "æ³¨æ„é£é™© âš ï¸"
            else: conclusion = "å»ºè®®å‡ä»“ ğŸ“‰"
            report_parts.append(f"### {data['name']} ({data['code']})\n- **é‡åŒ–è¯„åˆ†**: {score}\n- **ç»¼åˆç»“è®º**: {conclusion}\n- **è¯„åˆ†ä¾æ®**: {', '.join(reasons)}\n")
    return "\n".join(report_parts)
def call_gemini_ai(prompt):
    try:
        genai.configure(api_key=os.environ.get("GEMINI_API_KEY"))
        return genai.GenerativeModel("gemini-1.5-flash").generate_content(prompt).text
    except Exception as e: return f"AIæ¨¡å‹è°ƒç”¨å¤±è´¥: {e}"
def generate_ai_based_report(news, sectors, funds_string, macro_data):
    if not funds_string.strip(): return "ç”±äºæœªèƒ½è·å–ä»»ä½•åŸºé‡‘çš„è¯¦ç»†æ•°æ®ï¼ŒAIç­–ç•¥å¤§è„‘æ— æ³•è¿›è¡Œåˆ†æã€‚"
    analysis_prompt = f"""ä½œä¸ºä¸€åé¡¶çº§çš„ä¸­å›½å¸‚åœºå¯¹å†²åŸºé‡‘ç»ç†ï¼Œè¯·ç»“åˆä»¥ä¸‹æ‰€æœ‰ä¿¡æ¯ï¼Œæ’°å†™ä¸€ä»½åŒ…å«å®è§‚ã€ä¸­è§‚ã€å¾®è§‚ä¸‰ä¸ªå±‚æ¬¡çš„æ·±åº¦æŠ•ç ”æŠ¥å‘Š...\n**ç¬¬ä¸€éƒ¨åˆ†ï¼šä¸­å›½å®è§‚ç»æµèƒŒæ™¯ (æ¥æº: AkShare)**\n{macro_data}\n**ç¬¬äºŒéƒ¨åˆ†ï¼šå¸‚åœºæ–°é—»ä¸æƒ…ç»ª**\n{news}\n**ç¬¬ä¸‰éƒ¨åˆ†ï¼šä¸­è§‚è¡Œä¸šä¸æ¿å—è½®åŠ¨**\n{sectors}\n**ç¬¬å››éƒ¨åˆ†ï¼šå¾®è§‚æŒä»“åŸºé‡‘æŠ€æœ¯çŠ¶æ€ (æ¥æº: AkShare)**\n{funds_string}"""
    draft = call_gemini_ai(analysis_prompt)
    if "AIæ¨¡å‹è°ƒç”¨å¤±è´¥" in draft: return draft
    polish_prompt = f"ä½œä¸ºä¸€åå–„äºç”¨æ•°æ®è®²æ•…äº‹çš„æŠ•èµ„KOLï¼Œè¯·å°†ä»¥ä¸‹è¿™ä»½ä¸“ä¸šçš„æŠ•ç ”æŠ¥å‘Šï¼Œè½¬åŒ–ä¸ºä¸€ç¯‡æ™®é€šæŠ•èµ„è€…éƒ½èƒ½çœ‹æ‡‚çš„ç²¾å½©æ–‡ç« ...\n**ã€åŸå§‹æŠ¥å‘Šã€‘**\n{draft}"
    return call_gemini_ai(polish_prompt)
    
def main():
    if not check_time_interval(): return
    config, beijing_time = load_config(), datetime.datetime.utcnow() + datetime.timedelta(hours=8)
    structured_fund_datas, formatted_fund_strings, macro_data, news_text, sector_text = [], [], "", "", ""

    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:
        future_funds = {executor.submit(get_fund_data_from_akshare, c): c for c in config['fund_codes']}
        future_macro = executor.submit(get_china_macro_data_from_akshare, config['china_macro_indicators'])
        future_news = {executor.submit(search_news, kw): kw for kw in config['news_keywords']}
        future_sector = executor.submit(get_sector_data)

        for future in concurrent.futures.as_completed(future_funds):
            code = future_funds[future]
            try:
                name, df = future.result()
                structured, formatted = process_fund_data(name, df, code, config['moving_average_days'], config['historical_days_to_display'])
                if structured: structured_fund_datas.append(structured); formatted_fund_strings.append(formatted)
            except Exception as e: print(f"è·å–å¹¶å¤„ç†åŸºé‡‘ {code} æ—¶å‘ç”Ÿé¡¶å±‚é”™è¯¯: {e}")
        
        macro_data = future_macro.result()
        news_text = "\n".join([f.result() for f in concurrent.futures.as_completed(future_news)])
        sector_text = future_sector.result()

    if not os.path.exists('reports'): os.makedirs('reports')
    
    rule_report = generate_rule_based_report(structured_fund_datas, macro_data, beijing_time)
    with open(f"reports/åŸºé‡‘åˆ†ææŠ¥å‘Š-è§„åˆ™ç‰ˆ_{beijing_time.strftime('%Y-%m-%d')}.md", 'w', encoding='utf-8') as f: f.write(rule_report)
    print(f"\nâœ… â€œè§„åˆ™å¤§è„‘â€æŠ¥å‘Šå·²æˆåŠŸä¿å­˜ã€‚")

    ai_report = generate_ai_based_report(news_text, sector_text, "\n".join(formatted_fund_strings), macro_data)
    with open(f"reports/åŸºé‡‘åˆ†ææŠ¥å‘Š-AIç‰ˆ_{beijing_time.strftime('%Y-%m-%d')}.md", 'w', encoding='utf-8') as f: f.write(ai_report)
    print(f"âœ… â€œAIç­–ç•¥å¤§è„‘â€æŠ¥å‘Šå·²æˆåŠŸä¿å­˜ã€‚")

    update_timestamp()

if __name__ == "__main__":
    main()
