import os
import datetime
import time
import json
import concurrent.futures
import traceback
import google.generativeai as genai
import requests
import numpy as np
import pandas as pd
from bs4 import BeautifulSoup
from duckduckgo_search import DDGS

# --- å…¨å±€è®¾ç½® ---
HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36', 'Referer': 'http://fund.eastmoney.com/'}
TIMESTAMP_FILE = "last_run_timestamp.txt"
MIN_INTERVAL_HOURS = 6
REQUESTS_TIMEOUT = 20

# --- åŠŸèƒ½å‡½æ•° ---
def load_config():
    """ä»config.jsonåŠ è½½é…ç½®"""
    print("æ­£åœ¨åŠ è½½é…ç½®æ–‡ä»¶ config.json...")
    with open('config.json', 'r', encoding='utf-8') as f:
        config = json.load(f)
    config.setdefault('historical_days_to_display', 7)
    return config

def check_time_interval():
    github_event_name = os.getenv('GITHUB_EVENT_NAME')
    if github_event_name != 'repository_dispatch': return True
    if not os.path.exists(TIMESTAMP_FILE): return True
    with open(TIMESTAMP_FILE, "r") as f: last_run_timestamp = float(f.read())
    current_timestamp = time.time()
    hours_diff = (current_timestamp - last_run_timestamp) / 3600
    if hours_diff < MIN_INTERVAL_HOURS:
        print(f"è·ç¦»ä¸Šæ¬¡æ‰§è¡Œï¼ˆ{hours_diff:.2f}å°æ—¶ï¼‰æœªè¶…è¿‡{MIN_INTERVAL_HOURS}å°æ—¶ï¼Œæœ¬æ¬¡è·³è¿‡ã€‚")
        return False
    return True

def update_timestamp():
    with open(TIMESTAMP_FILE, "w") as f: f.write(str(time.time()))

def search_news(keyword):
    print(f"æ­£åœ¨æœç´¢æ–°é—»: {keyword}...")
    try:
        with DDGS() as ddgs:
            return "\n".join([f"- [æ ‡é¢˜] {r['title']}\n  [æ‘˜è¦] {r.get('body', 'æ— ')}\n" for r in ddgs.news(keyword, region='cn-zh', safesearch='off', max_results=5)])
    except Exception as e: return f"æœç´¢å…³é”®è¯ '{keyword}' å¤±è´¥: {e}"

def get_sector_data():
    print("æ­£åœ¨çˆ¬å–è¡Œä¸šæ¿å—æ•°æ®...")
    url = "http://quote.eastmoney.com/center/boardlist.html#industry_board"
    try:
        response = requests.get(url, headers=HEADERS, timeout=REQUESTS_TIMEOUT)
        soup = BeautifulSoup(response.text, 'html.parser')
        sectors = [{'name': cols[1].find('a').text.strip(), 'change': float(cols[4].text.strip().replace('%', ''))} for row in soup.select('table#table_wrapper-table tbody tr') if len(cols := row.find_all('td')) > 5]
        sectors.sort(key=lambda x: x['change'], reverse=True)
        rising_str = "\n".join([f"  - {s['name']}: {s['change']:.2f}%" for s in sectors[:10]])
        falling_str = "\n".join([f"  - {s['name']}: {s['change']:.2f}%" for s in sectors[-10:]])
        return f"**ã€çƒ­é—¨ä¸Šæ¶¨æ¿å—ã€‘**\n{rising_str}\n\n**ã€çƒ­é—¨ä¸‹è·Œæ¿å—ã€‘**\n{falling_str}"
    except Exception as e: return f"è¡Œä¸šæ¿å—æ•°æ®çˆ¬å–å¤±è´¥: {e}"

def get_fund_raw_data(fund_code, history_days):
    print(f"æ­£åœ¨è·å–åŸºé‡‘ {fund_code} çš„åŸå§‹æ•°æ®...")
    url = f"http://api.fund.eastmoney.com/f10/lsjz?fundCode={fund_code}&pageIndex=1&pageSize={history_days}"
    response = requests.get(url, headers=HEADERS, timeout=REQUESTS_TIMEOUT).json()
    return response['Data']

def process_fund_data(raw_data, fund_code, ma_days, days_to_display):
    """å¤„ç†åŸå§‹æ•°æ®ï¼Œè¿”å›ç»“æ„åŒ–æ•°æ®å’Œæ ¼å¼åŒ–å­—ç¬¦ä¸²"""
    print(f"æ­£åœ¨å¤„ç†åŸºé‡‘ {fund_code} çš„æ•°æ®...")
    fund_name = raw_data['FundBaseInfo']['JJJC']
    df = pd.DataFrame(raw_data['LSJZList'])
    df['FSRQ'] = pd.to_datetime(df['FSRQ'])
    df['DWJZ'] = pd.to_numeric(df['DWJZ'])
    df['JZZZL'] = pd.to_numeric(df['JZZZL'])
    df = df.sort_values('FSRQ')
    
    df[f'MA{ma_days}'] = df['DWJZ'].rolling(window=ma_days).mean()
    
    latest_data = df.iloc[-1]
    latest_price = latest_data['DWJZ']
    latest_ma = latest_data[f'MA{ma_days}']
    
    # å‡†å¤‡ç»“æ„åŒ–æ•°æ®
    structured_data = {
        'name': fund_name, 'code': fund_code,
        'latest_price': latest_price, 'latest_ma': latest_ma,
        'daily_growth': latest_data['JZZZL'], 'ma_days': ma_days
    }
    
    # å‡†å¤‡æ ¼å¼åŒ–å­—ç¬¦ä¸²
    recent_df = df.tail(days_to_display).sort_values('FSRQ', ascending=False)
    table_rows = []
    for _, row in recent_df.iterrows():
        ma_val = row[f'MA{ma_days}']
        ma_str = f"{ma_val:.4f}" if not pd.isna(ma_val) else "N/A"
        trend_emoji = "ğŸ“ˆ" if row['DWJZ'] > ma_val else "ğŸ“‰" if not pd.isna(ma_val) else "ğŸ¤”"
        table_rows.append(f"| {row['FSRQ'].strftime('%Y-%m-%d')} | {row['DWJZ']:.4f}   | {ma_str}    | {trend_emoji}  |")
    
    formatted_string = f"""
### åŸºé‡‘: {fund_name} ({fund_code})
- **æœ€æ–°å‡€å€¼**: {latest_price:.4f} (æ—¥æœŸ: {latest_data['FSRQ'].strftime('%Y-%m-%d')})
- **{ma_days}æ—¥å‡çº¿**: {latest_ma:.4f if not pd.isna(latest_ma) else 'æ•°æ®ä¸è¶³'}
- **æŠ€æœ¯åˆ†æ**: å½“å‰å‡€å€¼åœ¨ {ma_days}æ—¥å‡çº¿**{'ä¹‹ä¸Š' if latest_price > latest_ma else 'ä¹‹ä¸‹'}**ï¼ŒçŸ­æœŸè¶‹åŠ¿å¯èƒ½**{'åå¼º' if latest_price > latest_ma else 'åå¼±'}**ã€‚
- **æœ€è¿‘ {days_to_display} æ—¥è¯¦ç»†æ•°æ®**:
| æ—¥æœŸ       | å•ä½å‡€å€¼ | {ma_days}æ—¥å‡çº¿ | è¶‹åŠ¿ |
|:-----------|:---------|:------------|:-----|
""" + "\n".join(table_rows)

    return structured_data, formatted_string

def generate_rule_based_report(fund_datas, sector_data, beijing_time):
    print("æ­£åœ¨ç”Ÿæˆâ€œè§„åˆ™å¤§è„‘â€åˆ†ææŠ¥å‘Š...")
    report_parts = [f"# åŸºé‡‘é‡åŒ–è§„åˆ™åˆ†ææŠ¥å‘Š ({beijing_time.strftime('%Y-%m-%d')})\n"]
    report_parts.append("æœ¬æŠ¥å‘Šç”±é¢„è®¾é‡åŒ–è§„åˆ™ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒã€‚\n")
    
    for data in fund_datas:
        score = 0
        reasons = []
        if not pd.isna(data['latest_ma']):
            if data['latest_price'] > data['latest_ma']:
                score += 2
                reasons.append(f"å‡€å€¼({data['latest_price']:.4f})åœ¨{data['ma_days']}æ—¥å‡çº¿({data['latest_ma']:.4f})ä¹‹ä¸Š")
            else:
                score -= 2
                reasons.append(f"å‡€å€¼({data['latest_price']:.4f})åœ¨{data['ma_days']}æ—¥å‡çº¿({data['latest_ma']:.4f})ä¹‹ä¸‹")
        
        if data['daily_growth'] > 0:
            score += 1
            reasons.append(f"å½“æ—¥ä¸Šæ¶¨({data['daily_growth']:.2f}%)")
        else:
            score -= 1
            reasons.append(f"å½“æ—¥ä¸‹è·Œ({data['daily_growth']:.2f}%)")
            
        if score == 3: conclusion = "å¼ºçƒˆçœ‹å¥½ ğŸš€"
        elif score == 1: conclusion = "è°¨æ…ä¹è§‚ ğŸ‘"
        elif score == -1: conclusion = "æ³¨æ„é£é™© âš ï¸"
        else: conclusion = "å»ºè®®å‡ä»“ ğŸ“‰"
        
        report_parts.append(f"### {data['name']} ({data['code']})\n- **é‡åŒ–è¯„åˆ†**: {score}\n- **ç»¼åˆç»“è®º**: {conclusion}\n- **è¯„åˆ†ä¾æ®**: {', '.join(reasons)}\n")
        
    report_parts.append("\n--- \n**å…è´£å£°æ˜**: æœ¬æŠ¥å‘Šç”±è‡ªåŠ¨åŒ–è§„åˆ™ç”Ÿæˆï¼Œä¸æ„æˆä»»ä½•æŠ•èµ„å»ºè®®ã€‚")
    return "\n".join(report_parts)

def generate_ai_based_report(news, sectors, funds_string):
    print("æ­£åœ¨è¯·æ±‚â€œAIç­–ç•¥å¤§è„‘â€ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
    analysis_prompt = f"ä½œä¸ºä¸€åæ•°æ®é©±åŠ¨çš„é‡åŒ–æŠ•èµ„ç­–ç•¥å¸ˆï¼Œè¯·ä¸¥æ ¼æ ¹æ®ä»¥ä¸‹ä¸‰æ–¹é¢ä¿¡æ¯ï¼Œæ’°å†™ä¸€ä»½é€»è¾‘ä¸¥å¯†ã€æœ‰æ•°æ®æ”¯æ’‘çš„æŠ•èµ„ç­–ç•¥æŠ¥å‘Š...\n[...è¿™é‡Œçœç•¥äº†ä¹‹å‰çš„è¯¦ç»†Prompt...]\n**ç¬¬ä¸€éƒ¨åˆ†ï¼šå®è§‚æ–°é—»**\n{news}\n**ç¬¬äºŒéƒ¨åˆ†ï¼šæ¿å—è½®åŠ¨**\n{sectors}\n**ç¬¬ä¸‰éƒ¨åˆ†ï¼šæŒä»“åŸºé‡‘è¯¦ç»†æ•°æ®**\n{funds_string}"
    draft_article = call_gemini_ai(analysis_prompt)
    
    if "AIæ¨¡å‹è°ƒç”¨å¤±è´¥" in draft_article:
        return draft_article # ç›´æ¥è¿”å›é”™è¯¯ä¿¡æ¯
        
    polish_prompt = f"ä½œä¸ºä¸€åå–„äºç”¨æ•°æ®è¯´è¯çš„æŠ•èµ„ç¤¾åŒºKOLï¼Œè¯·å°†ä»¥ä¸‹è¿™ä»½ä¸“ä¸šçš„æŠ•ç ”æŠ¥å‘Šï¼Œè½¬åŒ–ä¸ºä¸€ç¯‡å¯¹æ™®é€šæŠ•èµ„è€…æå…·å¸å¼•åŠ›å’Œè¯´æœåŠ›çš„æ–‡ç« ...\n[...è¿™é‡Œçœç•¥äº†ä¹‹å‰çš„è¯¦ç»†Prompt...]\n**ã€åŸå§‹æŠ¥å‘Šã€‘**\n{draft_article}"
    return call_gemini_ai(polish_prompt)
    
def call_gemini_ai(prompt):
    try:
        genai.configure(api_key=os.environ.get("GEMINI_API_KEY"))
        model = genai.GenerativeModel("gemini-1.5-flash")
        response = model.generate_content(prompt, request_options={'timeout': 180}) # å¢åŠ è¶…æ—¶
        return response.text
    except Exception as e:
        print(f"è°ƒç”¨ Gemini AI å¤±è´¥: {e}")
        traceback.print_exc()
        return "AIæ¨¡å‹è°ƒç”¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥æˆ–ç½‘ç»œè¿æ¥ã€‚"

def main():
    if not check_time_interval(): return
    config = load_config()
    beijing_time = datetime.datetime.utcnow() + datetime.timedelta(hours=8)
    
    # --- å¹¶è¡Œè·å–æ‰€æœ‰åŸå§‹æ•°æ® ---
    raw_fund_datas = {}
    all_news_text = ""
    sector_data_text = ""

    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:
        news_futures = {executor.submit(search_news, kw): kw for kw in config['news_keywords']}
        fund_futures = {executor.submit(get_fund_raw_data, code, config['historical_days_to_fetch']): code for code in config['fund_codes']}
        sector_future = executor.submit(get_sector_data)

        for future in concurrent.futures.as_completed(fund_futures):
            code = fund_futures[future]
            raw_fund_datas[code] = future.result()
        
        all_news_text = "\n".join([f.result() for f in concurrent.futures.as_completed(news_futures)])
        sector_data_text = sector_future.result()

    # --- æ•°æ®å¤„ç† ---
    structured_fund_datas = []
    formatted_fund_strings = []
    for code in config['fund_codes']:
        if code in raw_fund_datas:
            try:
                structured, formatted = process_fund_data(raw_fund_datas[code], code, config['moving_average_days'], config['historical_days_to_display'])
                structured_fund_datas.append(structured)
                formatted_fund_strings.append(formatted)
            except Exception as e:
                print(f"å¤„ç†åŸºé‡‘ {code} æ•°æ®æ—¶å‡ºé”™: {e}")

    # --- ç”Ÿæˆå¹¶ä¿å­˜æŠ¥å‘Š ---
    if not os.path.exists('reports'): os.makedirs('reports')

    # 1. ç”Ÿæˆè§„åˆ™æŠ¥å‘Š (æ°¸è¿œæ‰§è¡Œ)
    try:
        rule_report = generate_rule_based_report(structured_fund_datas, sector_data_text, beijing_time)
        rule_filename = f"reports/åŸºé‡‘åˆ†ææŠ¥å‘Š-è§„åˆ™ç‰ˆ_{beijing_time.strftime('%Y-%m-%d_%H-%M')}.md"
        with open(rule_filename, 'w', encoding='utf-8') as f: f.write(rule_report)
        print(f"\nâœ… â€œè§„åˆ™å¤§è„‘â€æŠ¥å‘Šå·²æˆåŠŸä¿å­˜ä¸º: {rule_filename}")
    except Exception as e:
        print(f"\nâŒ ç”Ÿæˆâ€œè§„åˆ™å¤§è„‘â€æŠ¥å‘Šå¤±è´¥: {e}")

    # 2. ç”ŸæˆAIæŠ¥å‘Š (å¦‚æœå¤±è´¥ä¸å½±å“ç¨‹åº)
    try:
        ai_report = generate_ai_based_report(all_news_text, sector_data_text, "\n".join(formatted_fund_strings))
        ai_filename = f"reports/åŸºé‡‘åˆ†ææŠ¥å‘Š-AIç‰ˆ_{beijing_time.strftime('%Y-%m-%d_%H-%M')}.md"
        with open(ai_filename, 'w', encoding='utf-8') as f: f.write(ai_report)
        print(f"âœ… â€œAIç­–ç•¥å¤§è„‘â€æŠ¥å‘Šå·²æˆåŠŸä¿å­˜ä¸º: {ai_filename}")
    except Exception as e:
        print(f"\nâŒ ç”Ÿæˆâ€œAIç­–ç•¥å¤§è„‘â€æŠ¥å‘Šå¤±è´¥: {e}")

    update_timestamp()

if __name__ == "__main__":
    main()
