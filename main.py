import os
import datetime
import time
import concurrent.futures
import google.generativeai as genai
import requests
from bs4 import BeautifulSoup
from duckduckgo_search import DDGS

# --- ç”¨æˆ·é…ç½®åŒº ---
# è¯·åœ¨è¿™é‡Œè¾“å…¥æ‚¨å…³å¿ƒçš„åŸºé‡‘ä»£ç åˆ—è¡¨
FUND_CODES = ["001186", "161725", "005827"] 
# æ–°é—»æœç´¢çš„å…³é”®è¯
NEWS_KEYWORDS = ["ä¸­å›½è‚¡å¸‚", "Aè‚¡", "ç¾è”å‚¨åˆ©ç‡", "é‡è¦ç»æµä¼šè®®"]
# --- é…ç½®åŒºç»“æŸ ---

# --- å…¨å±€è®¾ç½® ---
# çªå‘äº‹ä»¶è§¦å‘çš„æœ€å°æ—¶é—´é—´éš”ï¼ˆå°æ—¶ï¼‰
MIN_INTERVAL_HOURS = 6
TIMESTAMP_FILE = "last_run_timestamp.txt"
MAX_NEWS_RESULTS = 5 # æ¯ä¸ªå…³é”®è¯æœç´¢çš„æ–°é—»æ•°é‡
REQUESTS_TIMEOUT = 15 # è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
SECTOR_COUNT = 10 # æŠ“å–æ¶¨è·Œå¹…å‰10çš„æ¿å—
# æ¨¡æ‹Ÿæµè§ˆå™¨è¯·æ±‚å¤´ï¼Œé˜²æ­¢è¢«ç½‘ç«™å±è”½
HEADERS = {
    'User-Agent': 'Mozilla.5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

def check_time_interval():
    """æ£€æŸ¥è·ç¦»ä¸Šæ¬¡çªå‘äº‹ä»¶æ‰§è¡Œæ˜¯å¦è¶…è¿‡æŒ‡å®šé—´éš”"""
    github_event_name = os.getenv('GITHUB_EVENT_NAME')
    if github_event_name != 'repository_dispatch':
        return True
    if not os.path.exists(TIMESTAMP_FILE):
        return True
    with open(TIMESTAMP_FILE, "r") as f:
        last_run_timestamp = float(f.read())
    current_timestamp = time.time()
    hours_diff = (current_timestamp - last_run_timestamp) / 3600
    if hours_diff < MIN_INTERVAL_HOURS:
        print(f"è·ç¦»ä¸Šæ¬¡æ‰§è¡Œï¼ˆ{hours_diff:.2f}å°æ—¶ï¼‰æœªè¶…è¿‡{MIN_INTERVAL_HOURS}å°æ—¶ï¼Œæœ¬æ¬¡è·³è¿‡ã€‚")
        return False
    return True

def update_timestamp():
    """æ›´æ–°æ—¶é—´æˆ³æ–‡ä»¶"""
    with open(TIMESTAMP_FILE, "w") as f:
        f.write(str(time.time()))

def search_news(keyword):
    """ä½¿ç”¨DuckDuckGoæœç´¢æ–°é—»"""
    print(f"æ­£åœ¨æœç´¢æ–°é—»å…³é”®è¯: {keyword}...")
    results = []
    try:
        with DDGS() as ddgs:
            ddgs_results = ddgs.news(keyword, region='cn-zh', safesearch='off', max_results=MAX_NEWS_RESULTS)
            if ddgs_results:
                for r in ddgs_results:
                    results.append(f"- [æ ‡é¢˜] {r['title']}\n  [é“¾æ¥] {r['url']}\n  [æ‘˜è¦] {r.get('body', 'æ— ')}\n")
    except Exception as e:
        print(f"æœç´¢å…³é”®è¯ '{keyword}' å¤±è´¥: {e}")
    return "\n".join(results)

def get_fund_data(fund_code):
    """çˆ¬å–å•æ”¯åŸºé‡‘çš„æ•°æ®"""
    print(f"æ­£åœ¨çˆ¬å–åŸºé‡‘æ•°æ®: {fund_code}...")
    url = f"http://fund.eastmoney.com/{fund_code}.html"
    try:
        response = requests.get(url, headers=HEADERS, timeout=REQUESTS_TIMEOUT)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        fund_name = soup.select_one('div.fundDetail-tit > div').get_text(strip=True).replace('(å‰ç«¯)', '')
        data_item = soup.select_one('dl.dataItem02')
        net_value = data_item.select_one('dd.dataNums > span.ui-font-large').text
        daily_growth = data_item.select_one('dd.dataNums > span:nth-of-type(2)').text
        data_info = soup.select_one('div.dataOfFund')
        fund_scale = data_info.select_one('td:nth-of-type(2)').text.split('ï¼š')[-1].strip()
        return f"""
### åŸºé‡‘: {fund_name} ({fund_code})
- **æœ€æ–°å‡€å€¼**: {net_value}
- **æ—¥å¢é•¿ç‡**: {daily_growth}
- **åŸºé‡‘è§„æ¨¡**: {fund_scale}
"""
    except Exception as e:
        print(f"çˆ¬å–åŸºé‡‘ {fund_code} æ•°æ®å¤±è´¥: {e}")
        return f"\n### åŸºé‡‘: {fund_code}\n- æ•°æ®çˆ¬å–å¤±è´¥ã€‚\n"

def get_sector_data():
    """çˆ¬å–è¡Œä¸šæ¿å—æ•°æ®ï¼ŒåŒ…æ‹¬æ¶¨å¹…å‰10å’Œè·Œå¹…å‰10"""
    print("æ­£åœ¨çˆ¬å–è¡Œä¸šæ¿å—æ•°æ®...")
    url = "http://quote.eastmoney.com/center/boardlist.html#industry_board"
    try:
        response = requests.get(url, headers=HEADERS, timeout=REQUESTS_TIMEOUT)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        
        table = soup.find('table', {'id': 'table_wrapper-table'})
        if not table:
            return "æœªèƒ½æ‰¾åˆ°æ¿å—æ•°æ®è¡¨æ ¼ï¼Œç½‘ç«™ç»“æ„å¯èƒ½å·²æ›´æ–°ã€‚"
        
        rows = table.select('tbody tr')
        
        sectors = []
        for row in rows:
            cols = row.find_all('td')
            if len(cols) > 5:
                try:
                    name = cols[1].find('a').text.strip()
                    change = float(cols[4].text.strip().replace('%', ''))
                    leading_stock = cols[8].find('a').text.strip()
                    sectors.append({'name': name, 'change': change, 'stock': leading_stock})
                except (ValueError, AttributeError):
                    continue

        # æŒ‰æ¶¨è·Œå¹…æ’åº
        sectors.sort(key=lambda x: x['change'], reverse=True)
        
        # æå–æ¶¨å¹…å‰10å’Œè·Œå¹…å‰10
        top_rising = sectors[:SECTOR_COUNT]
        top_falling = sectors[-SECTOR_COUNT:]
        top_falling.reverse() # è®©è·Œå¹…æœ€å¤§çš„åœ¨æœ€å‰é¢

        result = ["**ã€ä»Šæ—¥çƒ­é—¨ä¸Šæ¶¨æ¿å—ã€‘**"]
        for i, s in enumerate(top_rising):
            result.append(f"{i+1}. **{s['name']}**: {s['change']:.2f}% (é¢†æ¶¨è‚¡: {s['stock']})")
        
        result.append("\n**ã€ä»Šæ—¥çƒ­é—¨ä¸‹è·Œæ¿å—ã€‘**")
        for i, s in enumerate(top_falling):
            result.append(f"{i+1}. **{s['name']}**: {s['change']:.2f}% (é¢†è·Œè‚¡: {s['stock']})")
            
        return "\n".join(result)

    except Exception as e:
        print(f"çˆ¬å–è¡Œä¸šæ¿å—æ•°æ®å¤±è´¥: {e}")
        return "è¡Œä¸šæ¿å—æ•°æ®çˆ¬å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç«™ç»“æ„æˆ–ç½‘ç»œè¿æ¥ã€‚"

def call_gemini_ai(prompt, model_name="gemini-1.5-flash"):
    """è°ƒç”¨Gemini AI"""
    print(f"æ­£åœ¨è°ƒç”¨ Gemini AI ({model_name})...")
    try:
        genai.configure(api_key=os.environ.get("GEMINI_API_KEY"))
        model = genai.GenerativeModel(model_name)
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        print(f"è°ƒç”¨ Gemini AI å¤±è´¥: {e}")
        return "AIæ¨¡å‹è°ƒç”¨å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆå†…å®¹ã€‚"

def main():
    """ä¸»å‡½æ•°"""
    if not check_time_interval():
        return
        
    print("å¼€å§‹æ‰§è¡ŒåŸºé‡‘åˆ†æå·¥ä½œæµ...")
    
    all_news_text = ""
    all_fund_data = ""
    sector_data_text = ""

    with concurrent.futures.ThreadPoolExecutor(max_workers=15) as executor:
        news_futures = {executor.submit(search_news, kw): kw for kw in NEWS_KEYWORDS}
        fund_futures = {executor.submit(get_fund_data, code): code for code in FUND_CODES}
        sector_future = executor.submit(get_sector_data)
        
        # æ”¶é›†ç»“æœ
        all_news_text = "\n".join([f.result() for f in concurrent.futures.as_completed(news_futures)])
        all_fund_data = "\n".join([f.result() for f in concurrent.futures.as_completed(fund_futures)])
        sector_data_text = sector_future.result()

    print("\n--- æ–°é—»æ•°æ®æ±‡æ€» ---")
    print(all_news_text)
    print("\n--- åŸºé‡‘æ•°æ®æ±‡æ€» ---")
    print(all_fund_data)
    print("\n--- è¡Œä¸šæ¿å—æ•°æ® ---")
    print(sector_data_text)
    
    # --- ç¬¬ä¸€æ­¥ï¼šAIåˆ†æå¹¶ç”Ÿæˆåˆç¨¿ ---
    analysis_prompt = f"""
ä½œä¸ºä¸€åé¡¶çº§çš„åŸºé‡‘æŠ•èµ„ç­–ç•¥å¸ˆï¼Œè¯·æ ¹æ®ä»¥ä¸‹æ‰€æœ‰ä¿¡æ¯ï¼Œä¸ºæˆ‘æ’°å†™ä¸€ä»½æ·±å…¥çš„æŠ•èµ„æ“ä½œåˆ†ææŠ¥å‘Šã€‚

**ã€å®è§‚å¸‚åœºæ–°é—»æ‘˜è¦ã€‘**
{all_news_text}

**ã€ä»Šæ—¥è¡Œä¸šæ¿å—æ•°æ®æ¦‚è§ˆã€‘**
{sector_data_text}

**ã€æˆ‘å…³æ³¨çš„åŸºé‡‘æ ¸å¿ƒæ•°æ®ã€‘**
{all_fund_data}

**ã€æŠ¥å‘Šæ’°å†™è¦æ±‚ã€‘**
1.  **å¸‚åœºå¤§åŠ¿ç ”åˆ¤**: ç»“åˆã€å®è§‚æ–°é—»ã€‘å’Œã€è¡Œä¸šæ¿å—æ•°æ®ã€‘ï¼Œåˆ†æå½“å‰å¸‚åœºçš„æ•´ä½“æƒ…ç»ªï¼ˆä¹è§‚/æ‚²è§‚/ä¸­æ€§ï¼‰å’Œä¸»è¦ç‰¹å¾ï¼ˆä¾‹å¦‚ï¼Œæ˜¯æ™®æ¶¨æ™®è·Œï¼Œè¿˜æ˜¯ç»“æ„æ€§è¡Œæƒ…ï¼‰ã€‚
2.  **æ¿å—è½®åŠ¨åˆ†æ**: æ ¹æ®æ¿å—çš„æ¶¨è·Œæƒ…å†µï¼Œåˆ†æå½“å‰å¸‚åœºçš„çƒ­ç‚¹åœ¨å“ªé‡Œï¼Œèµ„é‡‘å¯èƒ½æ­£åœ¨ä»å“ªäº›æ¿å—æµå‡ºï¼Œåˆæµå‘äº†å“ªäº›æ¿å—ã€‚
3.  **æŒä»“åŸºé‡‘è¯Šæ–­**: é€ä¸€åˆ†ææˆ‘å…³æ³¨çš„æ¯ä¸€æ”¯åŸºé‡‘ã€‚è¯·åŠ¡å¿…å°†åŸºé‡‘çš„è¡¨ç°ä¸ã€è¡Œä¸šæ¿å—æ•°æ®ã€‘å…³è”èµ·æ¥ã€‚ä¾‹å¦‚ï¼Œå¦‚æœåŸºé‡‘é‡ä»“äº†æŸä¸ªçƒ­é—¨æ¿å—ï¼Œè¦æŒ‡å‡ºå…¶å—ç›Šæƒ…å†µï¼›å¦‚æœé‡ä»“äº†ä¸‹è·Œæ¿å—ï¼Œè¦åˆ†æå…¶å—æŒ«åŸå› ã€‚
4.  **ç»¼åˆæ“ä½œå»ºè®®**: åŸºäºä»¥ä¸Šæ‰€æœ‰ä¿¡æ¯çš„ç»¼åˆåˆ†æï¼Œç»™å‡ºæ˜ç¡®ã€å¯æ‰§è¡Œçš„æ€»ä½“æ“ä½œå»ºè®®ï¼ˆä¾‹å¦‚ï¼šå»ºè®®åŠ ä»“XXåŸºé‡‘ï¼Œå‡ä»“YYåŸºé‡‘ï¼Œæˆ–æ•´ä½“æŒä»“è§‚æœ›ï¼‰ã€‚æ“ä½œç†ç”±å¿…é¡»å……åˆ†ï¼Œè¦åŒæ—¶å¼•ç”¨æ–°é—»ã€æ¿å—å’ŒåŸºé‡‘æ•°æ®ä½œä¸ºè®ºæ®ã€‚
5.  **é£é™©æ­ç¤º**: æ˜ç¡®æŒ‡å‡ºå½“å‰å¸‚åœºå’Œæ“ä½œå»ºè®®ä¸­æ½œåœ¨çš„ä¸»è¦é£é™©ç‚¹ã€‚
6.  è¦æ±‚é€»è¾‘ä¸¥å¯†ï¼Œåˆ†ææ·±å…¥ï¼Œè¯­è¨€ä¸“ä¸šã€‚
"""
    
    draft_article = call_gemini_ai(analysis_prompt)
    print("\n--- AI ç”Ÿæˆçš„åˆ†ææŠ¥å‘Šåˆç¨¿ ---")
    print(draft_article)
    
    # --- ç¬¬äºŒæ­¥ï¼šAIæ¶¦è‰²æ–‡ç« ï¼Œç”¨äºç¤¾åŒºå‘è¡¨ ---
    polish_prompt = f"""
ä½œä¸ºä¸€åèµ„æ·±çš„æŠ•èµ„ç¤¾åŒºå†…å®¹åˆ›ä½œè€…ï¼Œè¯·å°†ä»¥ä¸‹è¿™ä»½ä¸“ä¸šçš„åˆ†ææŠ¥å‘Šæ¶¦è‰²æˆä¸€ç¯‡é€‚åˆåœ¨ç½‘ç»œç¤¾åŒºï¼ˆå¦‚é›ªçƒã€çŸ¥ä¹ï¼‰å‘è¡¨çš„æ–‡ç« ã€‚

**ã€åŸå§‹æŠ¥å‘Šã€‘**
{draft_article}

**ã€æ¶¦è‰²è¦æ±‚ã€‘**
1.  **æ ‡é¢˜**: èµ·ä¸€ä¸ªå¸å¼•äººä½†ä¸è¿‡äºå¤¸å¼ çš„æ ‡é¢˜ï¼Œæœ€å¥½èƒ½ä½“ç°å‡ºå¸‚åœºçš„æ ¸å¿ƒåŠ¨æ€ã€‚
2.  **å¼•è¨€**: å†™ä¸€æ®µå¼•äººå…¥èƒœçš„å¼€åœºç™½ï¼Œç”¨é€šä¿—çš„è¯æ¦‚æ‹¬ä¸€ä¸‹ä»Šå¤©çš„å¸‚åœºï¼ˆæ¯”å¦‚â€œä»Šå¤©åˆæ˜¯å–é…’åƒè¯è¡Œæƒ…â€ï¼Œæˆ–è€…â€œç§‘æŠ€è‚¡ä¸Šæ¼”å¤§æ’¤é€€â€ï¼‰ï¼Œå¹¶ç‚¹å‡ºæœ¬æ–‡çš„çœ‹ç‚¹ã€‚
3.  **æ­£æ–‡**: ä¿æŒåŸæ–‡çš„æ ¸å¿ƒé€»è¾‘å’Œæ•°æ®ä¸å˜ã€‚å°†ä¸“ä¸šçš„æœ¯è¯­è½¬åŒ–ä¸ºæ™®é€šæŠ•èµ„è€…èƒ½æ‡‚çš„å¤§ç™½è¯ã€‚å¯ä»¥é€‚å½“ä½¿ç”¨emojiæ¥å¢åŠ æ–‡ç« çš„ç”ŸåŠ¨æ€§ã€‚ä¾‹å¦‚ï¼ŒğŸ“ˆè¡¨ç¤ºä¸Šæ¶¨ï¼ŒğŸ“‰è¡¨ç¤ºä¸‹è·Œã€‚
4.  **ç»“å°¾**: è¿›è¡Œè¦ç‚¹æ€»ç»“ï¼Œå¹¶åŠ ä¸Šä¸€äº›é¼“åŠ±è¯»è€…äº’åŠ¨ã€è®¨è®ºçš„è¯è¯­ã€‚
5.  **å…è´£å£°æ˜**: åœ¨æ–‡ç« æœ«å°¾å¿…é¡»åŠ ä¸Šå…è´£å£°æ˜ï¼Œæç¤ºâ€œæœ¬æ–‡ä»…ä¸ºä¸ªäººè§‚ç‚¹åˆ†äº«ï¼Œä¸æ„æˆä»»ä½•æŠ•èµ„å»ºè®®ï¼Œå¸‚åœºæœ‰é£é™©ï¼ŒæŠ•èµ„éœ€è°¨æ…â€ã€‚
"""
    
    final_article = call_gemini_ai(polish_prompt)
    print("\n--- ç»AIæ¶¦è‰²åçš„æœ€ç»ˆæ–‡ç«  ---")
    print(final_article)
    
    # --- ä¿å­˜æ–‡ç« åˆ°æ–‡ä»¶ ---
    if not os.path.exists('reports'):
        os.makedirs('reports')
    beijing_time = datetime.datetime.utcnow() + datetime.timedelta(hours=8)
    file_name = f"reports/åŸºé‡‘åˆ†ææŠ¥å‘Š_{beijing_time.strftime('%Y-%m-%d_%H-%M')}.md"
    with open(file_name, 'w', encoding='utf-8') as f:
        f.write(final_article)
    print(f"\næŠ¥å‘Šå·²æˆåŠŸä¿å­˜ä¸º: {file_name}")

    update_timestamp()

if __name__ == "__main__":
    main()
