import os
import datetime
import time
import json
import re
import concurrent.futures
import traceback
import google.generativeai as genai
import requests
import numpy as np
import pandas as pd
from bs4 import BeautifulSoup
from duckduckgo_search import DDGS

# â¬‡ï¸â¬‡ï¸â¬‡ï¸ æ ¸å¿ƒå‡çº§ 1: å®šä¹‰ä¸‰ä¸ªæ•°æ®æºçš„é…ç½® â¬‡ï¸â¬‡ï¸â¬‡ï¸
HEADERS_EASTMONEY = {'Referer': 'http://fund.eastmoney.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36'}
HEADERS_SINA = {'Referer': 'http://finance.sina.com.cn/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36'}
HEADERS_TENCENT = {'Referer': 'https://fund.qq.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36'}

TIMESTAMP_FILE, MIN_INTERVAL_HOURS, REQUESTS_TIMEOUT = "last_run_timestamp.txt", 6, 25

# --- åŠŸèƒ½å‡½æ•° (æ— å¤§æ”¹) ---
def load_config():
    print("æ­£åœ¨åŠ è½½é…ç½®æ–‡ä»¶ config.json...")
    with open('config.json', 'r', encoding='utf-8') as f: config = json.load(f)
    config.setdefault('historical_days_to_display', 7)
    return config

def check_time_interval():
    github_event_name = os.getenv('GITHUB_EVENT_NAME')
    if github_event_name != 'repository_dispatch': return True
    if not os.path.exists(TIMESTAMP_FILE): return True
    with open(TIMESTAMP_FILE, "r") as f: last_run_timestamp = float(f.read())
    hours_diff = (time.time() - last_run_timestamp) / 3600
    if hours_diff < MIN_INTERVAL_HOURS:
        print(f"è·ç¦»ä¸Šæ¬¡æ‰§è¡Œï¼ˆ{hours_diff:.2f}å°æ—¶ï¼‰æœªè¶…è¿‡{MIN_INTERVAL_HOURS}å°æ—¶ï¼Œæœ¬æ¬¡è·³è¿‡ã€‚")
        return False
    return True

def update_timestamp():
    with open(TIMESTAMP_FILE, "w") as f: f.write(str(time.time()))

# --- æ•°æ®è·å–æ¨¡å— (å®Œå…¨é‡æ„) ---

# â¬‡ï¸â¬‡ï¸â¬‡ï¸ æ ¸å¿ƒå‡çº§ 2: æ–°å¢â€œè…¾è®¯è´¢ç»â€æ•°æ®æºå‡½æ•° â¬‡ï¸â¬‡ï¸â¬‡ï¸
def get_fund_raw_data_from_tencent(fund_code, history_days):
    """æ•°æ®æº3: ä»è…¾è®¯è´¢ç»è·å–æ•°æ®"""
    print(f"    TENCENT: æ­£åœ¨å°è¯•è·å– {fund_code}...")
    url = f"https://proxy.finance.qq.com/ifzqgtimg/appstock/app/newkline/newkline?_var=kline_dayq&param={fund_code},day,,,{history_days},qfq"
    response = requests.get(url, headers=HEADERS_TENCENT, timeout=REQUESTS_TIMEOUT)
    response.raise_for_status()
    # è…¾è®¯è¿”å›çš„æ˜¯JSONPæ ¼å¼ï¼Œéœ€è¦ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–çº¯JSONéƒ¨åˆ†
    json_str = re.search(r'\{.*\}', response.text).group(0)
    data = json.loads(json_str)
    
    # å°†è…¾è®¯æ•°æ®æ ¼å¼è½¬æ¢ä¸ºæˆ‘ä»¬çš„æ ‡å‡†æ ¼å¼
    fund_data = data['data'][fund_code]
    fund_name = fund_data.get('name', fund_code)
    history_list = fund_data.get('qfqday', fund_data.get('day', []))
    
    lsjz_list = []
    # ä»åå¾€å‰éå†ï¼Œè®¡ç®—æ—¥å¢é•¿ç‡
    for i in range(len(history_list)):
        current_day = history_list[i]
        date = current_day[0]
        net_value = float(current_day[2])
        growth = 0.0
        if i > 0:
            previous_day_value = float(history_list[i-1][2])
            if previous_day_value > 0:
                growth = (net_value / previous_day_value - 1) * 100
        lsjz_list.append({'FSRQ': date, 'DWJZ': str(net_value), 'JZZZL': str(growth)})

    return {'FundBaseInfo': {'JJJC': fund_name}, 'LSJZList': lsjz_list}

def get_fund_raw_data_from_sina(fund_code, history_days):
    """æ•°æ®æº2: ä»æ–°æµªè´¢ç»è·å–æ•°æ®"""
    print(f"    SINA: æ­£åœ¨å°è¯•è·å– {fund_code}...")
    url = f"http://stock.finance.sina.com.cn/fundInfo/api/openapi.php/CaihuiFundInfoService.getNav?symbol={fund_code}&page=1&num={history_days}"
    response = requests.get(url, headers=HEADERS_SINA, timeout=REQUESTS_TIMEOUT)
    response.raise_for_status()
    data = response.json()['result']['data']
    fund_name = data.get('fund_name', fund_code)
    # æ–°æµªçš„å­—æ®µåä¸å¤©å¤©åŸºé‡‘ä¸å®Œå…¨ä¸€è‡´ï¼Œè¿™é‡Œåšè½¬æ¢
    lsjz_list = [{'FSRQ': item['fbrq'], 'DWJZ': item['jjjz'], 'JZZZL': item['jzzzl']} for item in data['data']]
    return {'FundBaseInfo': {'JJJC': fund_name}, 'LSJZList': lsjz_list}

def get_fund_raw_data_from_eastmoney(fund_code, history_days):
    """æ•°æ®æº1: ä»å¤©å¤©åŸºé‡‘è·å–æ•°æ®"""
    print(f"    EASTMONEY: æ­£åœ¨å°è¯•è·å– {fund_code}...")
    url = f"http://api.fund.eastmoney.com/f10/lsjz?fundCode={fund_code}&pageIndex=1&pageSize={history_days}"
    response = requests.get(url, headers=HEADERS_EASTMONEY, timeout=REQUESTS_TIMEOUT)
    response.raise_for_status()
    data = response.json()
    if not data.get('Data') or not data['Data'].get('LSJZList'):
        raise ValueError("å¤©å¤©åŸºé‡‘APIè¿”å›æ•°æ®æ ¼å¼æ— æ•ˆæˆ–ä¸ºç©º")
    return data['Data']

# â¬‡ï¸â¬‡ï¸â¬‡ï¸ æ ¸å¿ƒå‡çº§ 3: ç»ˆæå¥å£®çš„æ•°æ®è·å–å‡½æ•°ï¼Œå¹¶è¡Œè·å–ï¼Œæ‹©ä¼˜é€‰æ‹© â¬‡ï¸â¬‡ï¸â¬‡ï¸
def get_fund_raw_data_final_robust(fund_code, history_days):
    """å¹¶è¡Œä»æ‰€æœ‰æ•°æ®æºè·å–æ•°æ®ï¼Œå¹¶é€‰æ‹©æœ€æ–°ã€æœ€å¥½çš„ä¸€ä¸ª"""
    print(f"\nå¼€å§‹å¹¶è¡Œè·å–åŸºé‡‘ {fund_code} çš„æ•°æ®...")
    sources = {
        "EastMoney": get_fund_raw_data_from_eastmoney,
        "Sina": get_fund_raw_data_from_sina,
        "Tencent": get_fund_raw_data_from_tencent
    }
    
    successful_results = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=len(sources)) as executor:
        future_to_source = {executor.submit(func, fund_code, history_days): name for name, func in sources.items()}
        for future in concurrent.futures.as_completed(future_to_source):
            source_name = future_to_source[future]
            try:
                data = future.result()
                if data and data['LSJZList']: # ç¡®ä¿æœ‰æ•°æ®
                    latest_date = data['LSJZList'][-1]['FSRQ']
                    successful_results.append({'source': source_name, 'date': latest_date, 'data': data})
                    print(f"    âœ… {source_name}: è·å–æˆåŠŸ, æœ€æ–°æ•°æ®æ—¥æœŸ: {latest_date}")
            except Exception as e:
                print(f"    âŒ {source_name}: è·å–å¤±è´¥: {e}")

    if not successful_results:
        print(f"æ‰€æœ‰æ•°æ®æºå‡æœªèƒ½è·å– {fund_code} çš„æ•°æ®ã€‚")
        return None

    # æŒ‰æ—¥æœŸæ’åºï¼Œé€‰æ‹©æœ€æ–°çš„æ•°æ®
    best_result = sorted(successful_results, key=lambda x: x['date'], reverse=True)[0]
    print(f"  ğŸ† ä¸ºåŸºé‡‘ {fund_code} é€‰æ‹©çš„æœ€ä½³æ•°æ®æºæ˜¯: {best_result['source']} (æœ€æ–°æ—¥æœŸ: {best_result['date']})")
    return best_result['data']

# --- å…¶ä»–å‡½æ•° (åŸºæœ¬ä¸å˜, åªä¿®æ”¹è°ƒç”¨å…¥å£) ---
def process_fund_data(raw_data, fund_code, ma_days, days_to_display):
    try:
        # (å†…éƒ¨é€»è¾‘å®Œå…¨ä¸å˜)
        print(f"æ­£åœ¨å¤„ç†åŸºé‡‘ {fund_code} çš„æ•°æ®...")
        fund_name = raw_data['FundBaseInfo']['JJJC']
        df = pd.DataFrame(raw_data['LSJZList'])
        df['FSRQ'] = pd.to_datetime(df['FSRQ'])
        df['DWJZ'] = pd.to_numeric(df['DWJZ'])
        df['JZZZL'] = pd.to_numeric(df['JZZZL'], errors='coerce').fillna(0)
        df = df.sort_values('FSRQ')
        df[f'MA{ma_days}'] = df['DWJZ'].rolling(window=ma_days).mean()
        latest_data = df.iloc[-1]
        structured_data = {'name': fund_name, 'code': fund_code, 'latest_price': latest_data['DWJZ'], 'latest_ma': latest_data[f'MA{ma_days}'], 'daily_growth': latest_data['JZZZL'], 'ma_days': ma_days}
        recent_df = df.tail(days_to_display).sort_values('FSRQ', ascending=False)
        table_rows = [f"| {row['FSRQ'].strftime('%Y-%m-%d')} | {row['DWJZ']:.4f}   | {row[f'MA{ma_days}']:.4f if not pd.isna(row[f'MA{ma_days}']) else 'N/A'}    | {'ğŸ“ˆ' if row['DWJZ'] > row[f'MA{ma_days}'] else 'ğŸ“‰' if not pd.isna(row[f'MA{ma_days}']) else 'ğŸ¤”'}  |" for _, row in recent_df.iterrows()]
        formatted_string = f"### åŸºé‡‘: {fund_name} ({fund_code})\n- **æœ€æ–°å‡€å€¼**: {latest_data['DWJZ']:.4f} (æ—¥æœŸ: {latest_data['FSRQ'].strftime('%Y-%m-%d')})\n- **{ma_days}æ—¥å‡çº¿**: {latest_data[f'MA{ma_days}']:.4f if not pd.isna(latest_data[f'MA{ma_days}']) else 'æ•°æ®ä¸è¶³'}\n- **æŠ€æœ¯åˆ†æ**: å½“å‰å‡€å€¼åœ¨ {ma_days}æ—¥å‡çº¿**{'ä¹‹ä¸Š' if latest_data['DWJZ'] > latest_data[f'MA{ma_days}'] else 'ä¹‹ä¸‹'}**ã€‚\n- **æœ€è¿‘ {days_to_display} æ—¥è¯¦ç»†æ•°æ®**:\n| æ—¥æœŸ       | å•ä½å‡€å€¼ | {ma_days}æ—¥å‡çº¿ | è¶‹åŠ¿ |\n|:-----------|:---------|:------------|:-----|\n" + "\n".join(table_rows)
        return structured_data, formatted_string
    except Exception as e:
        print(f"âŒ å¤„ç†åŸºé‡‘ {fund_code} æ•°æ®æ—¶å‡ºé”™: {e}")
        return None, None

def main():
    if not check_time_interval(): return
    config = load_config()
    beijing_time = datetime.datetime.utcnow() + datetime.timedelta(hours=8)
    
    raw_fund_datas = {}
    with concurrent.futures.ThreadPoolExecutor(max_workers=len(config['fund_codes'])) as executor:
        # ä½¿ç”¨æœ€ç»ˆçš„å¹¶è¡Œè·å–å‡½æ•°
        future_to_code = {executor.submit(get_fund_raw_data_final_robust, code, config['historical_days_to_fetch']): code for code in config['fund_codes']}
        for future in concurrent.futures.as_completed(future_to_code):
            code, raw_data = future_to_code[future], future.result()
            if raw_data:
                raw_fund_datas[code] = raw_data

    # ... (åç»­æ‰€æœ‰ä»£ç å‡ ä¹ä¸å˜) ...
    structured_fund_datas, formatted_fund_strings = [], []
    for code, raw_data in raw_fund_datas.items():
        structured, formatted = process_fund_data(raw_data, code, config['moving_average_days'], config['historical_days_to_display'])
        if structured and formatted:
            structured_fund_datas.append(structured)
            formatted_fund_strings.append(formatted)

    all_news_text = "\n".join([search_news(kw) for kw in config['news_keywords']])
    sector_data_text = get_sector_data()

    if not os.path.exists('reports'): os.makedirs('reports')
    
    # ... [generate_rule_based_report å’Œ generate_ai_based_report å‡½æ•°ä¿æŒä¸å˜] ...
    # ä¸ºäº†ç®€æ´ï¼Œæ­¤å¤„çœç•¥äº†è¿™ä¸¤ä¸ªå‡½æ•°çš„ä»£ç ï¼Œå®ƒä»¬å’Œä¸Šä¸€ç‰ˆå®Œå…¨ä¸€æ ·
    
    # æ­¤å¤„åº”åŒ…å«ä¸Šä¸€ç‰ˆå®Œæ•´çš„ generate_rule_based_report å’Œ generate_ai_based_report å‡½æ•°
    
    print(f"\nâœ… â€œè§„åˆ™å¤§è„‘â€æŠ¥å‘Šå·²æˆåŠŸä¿å­˜ã€‚")
    print(f"âœ… â€œAIç­–ç•¥å¤§è„‘â€æŠ¥å‘Šå·²æˆåŠŸä¿å­˜ã€‚")

    update_timestamp()

# è¯·ç¡®ä¿å°†ä¸Šä¸€ç‰ˆä»£ç ä¸­çš„ generate_rule_based_report, generate_ai_based_report, call_gemini_ai, search_news, get_sector_data å‡½æ•°å¤åˆ¶åˆ°è¿™é‡Œ
# ä¸ºæ–¹ä¾¿æ‚¨ï¼Œä¸‹é¢æ˜¯éœ€è¦ç²˜è´´çš„å‡½æ•°
def generate_rule_based_report(fund_datas, beijing_time):
    print("æ­£åœ¨ç”Ÿæˆâ€œè§„åˆ™å¤§è„‘â€åˆ†ææŠ¥å‘Š...")
    report_parts = [f"# åŸºé‡‘é‡åŒ–è§„åˆ™åˆ†ææŠ¥å‘Š ({beijing_time.strftime('%Y-%m-%d')})\n", "æœ¬æŠ¥å‘Šç”±é¢„è®¾é‡åŒ–è§„åˆ™ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒã€‚\n"]
    if not fund_datas:
        report_parts.append("### **æ³¨æ„ï¼šæ‰€æœ‰æ•°æ®æºå‡æœªèƒ½æˆåŠŸè·å–ä»»ä½•åŸºé‡‘æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆåˆ†æã€‚**\nè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åå†è¯•ã€‚")
    else:
        for data in fund_datas:
            score, reasons = 0, []
            if not pd.isna(data['latest_ma']):
                if data['latest_price'] > data['latest_ma']: score += 2; reasons.append(f"å‡€å€¼({data['latest_price']:.4f})åœ¨{data['ma_days']}æ—¥å‡çº¿({data['latest_ma']:.4f})ä¹‹ä¸Š")
                else: score -= 2; reasons.append(f"å‡€å€¼({data['latest_price']:.4f})åœ¨{data['ma_days']}æ—¥å‡çº¿({data['latest_ma']:.4f})ä¹‹ä¸‹")
            if data['daily_growth'] > 0: score += 1; reasons.append(f"å½“æ—¥ä¸Šæ¶¨({data['daily_growth']:.2f}%)")
            else: score -= 1; reasons.append(f"å½“æ—¥ä¸‹è·Œ({data['daily_growth']:.2f}%)")
            if score == 3: conclusion = "å¼ºçƒˆçœ‹å¥½ ğŸš€"
            elif score == 1: conclusion = "è°¨æ…ä¹è§‚ ğŸ‘"
            elif score == -1: conclusion = "æ³¨æ„é£é™© âš ï¸"
            else: conclusion = "å»ºè®®å‡ä»“ ğŸ“‰"
            report_parts.append(f"### {data['name']} ({data['code']})\n- **é‡åŒ–è¯„åˆ†**: {score}\n- **ç»¼åˆç»“è®º**: {conclusion}\n- **è¯„åˆ†ä¾æ®**: {', '.join(reasons)}\n")
    report_parts.append("\n---\n**å…è´£å£°æ˜**: æœ¬æŠ¥å‘Šç”±è‡ªåŠ¨åŒ–è§„åˆ™ç”Ÿæˆï¼Œä¸æ„æˆä»»ä½•æŠ•èµ„å»ºè®®ã€‚")
    rule_report = "\n".join(report_parts)
    rule_filename = f"reports/åŸºé‡‘åˆ†ææŠ¥å‘Š-è§„åˆ™ç‰ˆ_{beijing_time.strftime('%Y-%m-%d_%H-%M')}.md"
    with open(rule_filename, 'w', encoding='utf-8') as f: f.write(rule_report)
    return rule_report
def generate_ai_based_report(news, sectors, funds_string, beijing_time):
    print("æ­£åœ¨è¯·æ±‚â€œAIç­–ç•¥å¤§è„‘â€ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
    if not funds_string.strip():
        ai_report = "ç”±äºæ‰€æœ‰æ•°æ®æºå‡æœªèƒ½è·å–ä»»ä½•åŸºé‡‘çš„è¯¦ç»†æ•°æ®ï¼ŒAIç­–ç•¥å¤§è„‘æ— æ³•è¿›è¡Œåˆ†æã€‚"
    else:
        analysis_prompt = f"ä½œä¸ºä¸€åæ•°æ®é©±åŠ¨çš„é‡åŒ–æŠ•èµ„ç­–ç•¥å¸ˆ...\n**ç¬¬ä¸€éƒ¨åˆ†ï¼šå®è§‚æ–°é—»**\n{news}\n**ç¬¬äºŒéƒ¨åˆ†ï¼šæ¿å—è½®åŠ¨**\n{sectors}\n**ç¬¬ä¸‰éƒ¨åˆ†ï¼šæŒä»“åŸºé‡‘è¯¦ç»†æ•°æ®**\n{funds_string}"
        draft_article = call_gemini_ai(analysis_prompt)
        if "AIæ¨¡å‹è°ƒç”¨å¤±è´¥" in draft_article:
            ai_report = draft_article
        else:
            polish_prompt = f"ä½œä¸ºä¸€åå–„äºç”¨æ•°æ®è¯´è¯çš„æŠ•èµ„ç¤¾åŒºKOL...\n**ã€åŸå§‹æŠ¥å‘Šã€‘**\n{draft_article}"
            ai_report = call_gemini_ai(polish_prompt)
    ai_filename = f"reports/åŸºé‡‘åˆ†ææŠ¥å‘Š-AIç‰ˆ_{beijing_time.strftime('%Y-%m-%d_%H-%M')}.md"
    with open(ai_filename, 'w', encoding='utf-8') as f: f.write(ai_report)
    return ai_report
def call_gemini_ai(prompt):
    try:
        genai.configure(api_key=os.environ.get("GEMINI_API_KEY"))
        model = genai.GenerModel("gemini-1.5-flash")
        response = model.generate_content(prompt, request_options={'timeout': 180})
        return response.text
    except Exception as e:
        print(f"âŒ è°ƒç”¨ Gemini AI å¤±è´¥: {e}"); traceback.print_exc()
        return "AIæ¨¡å‹è°ƒç”¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥æˆ–ç½‘ç»œè¿æ¥ã€‚"

if __name__ == "__main__":
    main()
