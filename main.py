import os
import datetime
import time
import json
import concurrent.futures
import traceback
import google.generativeai as genai
import requests
import pandas as pd
import yfinance as yf
import akshare as ak
from bs4 import BeautifulSoup
from ddgs import DDGS

# --- å…¨å±€é…ç½® ---
HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36'}
TIMESTAMP_FILE, MIN_INTERVAL_HOURS = "last_run_timestamp.txt", 6

# --- åŸºç¡€è¾…åŠ©å‡½æ•° ---
def load_config():
    with open('config.json', 'r', encoding='utf-8') as f: config = json.load(f)
    config.setdefault('historical_days_to_display', 7)
    return config

def check_time_interval():
    if os.getenv('GITHUB_EVENT_NAME') != 'repository_dispatch' or not os.path.exists(TIMESTAMP_FILE): return True
    with open(TIMESTAMP_FILE, "r") as f: last_run_timestamp = float(f.read())
    if (time.time() - last_run_timestamp) / 3600 < MIN_INTERVAL_HOURS: return False
    return True

def update_timestamp():
    with open(TIMESTAMP_FILE, "w") as f: f.write(str(time.time()))

# --- æ•°æ®è·å–æ¨¡å— (å®è§‚+å¾®è§‚) ---
def get_china_macro_data_from_akshare(indicators):
    print("    AKSHARE: æ­£åœ¨å¯åŠ¨ä¸­å›½å®è§‚ç»æµæ•°æ®æ ¸å¿ƒ...")
    macro_data_parts = ["**ã€ä¸­å›½æ ¸å¿ƒå®è§‚ç»æµæŒ‡æ ‡ (æ¥æº: å›½å®¶ç»Ÿè®¡å±€ç­‰)ã€‘**"]
    indicator_functions = {
        "CPI": ak.mac_cn_cpi_monthly, "PPI": ak.mac_cn_ppi_monthly,
        "M2": ak.mac_cn_m2_yearly, "PMI": ak.mac_cn_pmi_yearly
    }
    for indicator_id, name in indicators.items():
        try:
            if indicator_id in indicator_functions:
                df = indicator_functions[indicator_id]()
                latest_data = df.iloc[-1]
                date = latest_data.get('æœˆä»½', latest_data.get('ç»Ÿè®¡æ—¶é—´', 'N/A'))
                value = latest_data.get('å½“æœˆåŒæ¯”', latest_data.get('åˆ¶é€ ä¸šPMI', 'N/A'))
                macro_data_parts.append(f"- **{name} ({indicator_id})**: {value} (æˆªè‡³: {date})")
        except Exception as e:
            print(f"    AKSHARE: âŒ è·å–æŒ‡æ ‡ {name} å¤±è´¥: {e}")
            macro_data_parts.append(f"- **{name} ({indicator_id})**: è·å–å¤±è´¥")
    print("    AKSHARE: âœ… å®è§‚ç»æµæ•°æ®è·å–å®Œæˆã€‚")
    return "\n".join(macro_data_parts)

def get_fund_data_from_yfinance(fund_code, history_days, ma_days):
    print(f"    YFINANCE: æ­£åœ¨ä¸º {fund_code} å¯åŠ¨é›…è™è´¢ç»æ•°æ®æ ¸å¿ƒ...")
    tickers_to_try = [f"{fund_code}.SS", f"{fund_code}.SZ"]
    hist_df, ticker_used = None, ""
    for ticker in tickers_to_try:
        try:
            fund = yf.Ticker(ticker)
            hist_df = fund.history(period=f"{history_days + ma_days}d", auto_adjust=True)
            if not hist_df.empty:
                print(f"    YFINANCE: âœ… æˆåŠŸä½¿ç”¨ä»£ç  {ticker} è·å–åˆ°æ•°æ®ã€‚")
                ticker_used = ticker; break
        except Exception: continue
    if hist_df is None or hist_df.empty: raise ValueError(f"æ— æ³•åœ¨é›…è™è´¢ç»æ‰¾åˆ° {fund_code} çš„æ•°æ®ã€‚")
    
    hist_df.rename(columns={'Close': 'æ”¶ç›˜'}, inplace=True)
    hist_df['æ—¥å¢é•¿ç‡'] = hist_df['æ”¶ç›˜'].pct_change() * 100
    hist_df[f'MA{ma_days}'] = hist_df['æ”¶ç›˜'].rolling(window=ma_days).mean()
    try: fund_name = yf.Ticker(ticker_used).info.get('longName', fund_code)
    except Exception: fund_name = fund_code
    return fund_name, hist_df.tail(history_days)

# --- æ•°æ®å¤„ç†ä¸æŠ¥å‘Šç”Ÿæˆ ---
def process_fund_data(fund_name, hist_df, fund_code, ma_days, days_to_display):
    try:
        print(f"æ­£åœ¨å¤„ç†åŸºé‡‘ {fund_code} çš„æ•°æ®...")
        latest_data = hist_df.iloc[-1]
        structured = {'name': fund_name, 'code': fund_code, 'latest_price': latest_data['æ”¶ç›˜'], 'latest_ma': latest_data[f'MA{ma_days}'], 'daily_growth': latest_data['æ—¥å¢é•¿ç‡'], 'ma_days': ma_days}
        recent_df = hist_df.tail(days_to_display).sort_index(ascending=False)
        table_rows = [f"| {idx.strftime('%Y-%m-%d')} | {row['æ”¶ç›˜']:.4f} | {row[f'MA{ma_days}']:.4f if not pd.isna(row[f'MA{ma_days}']) else 'N/A'} | {'ğŸ“ˆ' if row['æ”¶ç›˜'] > row[f'MA{ma_days}'] else 'ğŸ“‰' if not pd.isna(row[f'MA{ma_days}']) else 'ğŸ¤”'} |" for idx, row in recent_df.iterrows()]
        formatted = f"### åŸºé‡‘: {fund_name} ({fund_code})\n- **æœ€æ–°å‡€å€¼**: {latest_data['æ”¶ç›˜']:.4f} (æˆªè‡³: {latest_data.name.strftime('%Y-%m-%d')})\n- **{ma_days}æ—¥å‡çº¿**: {latest_data[f'MA{ma_days}']:.4f if not pd.isna(latest_data[f'MA{ma_days}']) else 'æ•°æ®ä¸è¶³'}\n- **æœ€è¿‘ {days_to_display} æ—¥è¯¦ç»†æ•°æ®**:\n| æ—¥æœŸ | å•ä½å‡€å€¼ | {ma_days}æ—¥å‡çº¿ | è¶‹åŠ¿ |\n|:---|:---|:---|:---|\n" + "\n".join(table_rows)
        return structured, formatted
    except Exception as e:
        print(f"âŒ å¤„ç†åŸºé‡‘ {fund_code} æ•°æ®æ—¶å‡ºé”™: {e}"); traceback.print_exc()
        return None, None

def search_news(keyword):
    print(f"æ­£åœ¨æœç´¢æ–°é—»: {keyword}...")
    with DDGS() as ddgs: return "\n".join([f"- [æ ‡é¢˜] {r['title']}\n  [æ‘˜è¦] {r.get('body', 'æ— ')}\n" for r in ddgs.news(keyword, region='cn-zh', max_results=5)])

def get_sector_data():
    print("æ­£åœ¨çˆ¬å–è¡Œä¸šæ¿å—æ•°æ®...")
    try:
        response = requests.get("http://quote.eastmoney.com/center/boardlist.html#industry_board", headers=HEADERS, timeout=30)
        soup = BeautifulSoup(response.text, 'html.parser')
        sectors = [{'name': c[1].find('a').text.strip(), 'change': float(c[4].text.replace('%',''))} for r in soup.select('table#table_wrapper-table tbody tr') if len(c:=r.find_all('td'))>5]
        sectors.sort(key=lambda x: x['change'], reverse=True)
        rising = "\n".join([f"  - {s['name']}: {s['change']:.2f}%" for s in sectors[:10]])
        falling = "\n".join([f"  - {s['name']}: {s['change']:.2f}%" for s in sectors[-10:]])
        return f"**ã€çƒ­é—¨ä¸Šæ¶¨æ¿å—ã€‘**\n{rising}\n\n**ã€çƒ­é—¨ä¸‹è·Œæ¿å—ã€‘**\n{falling}"
    except Exception as e: return f"è¡Œä¸šæ¿å—æ•°æ®çˆ¬å–å¤±è´¥: {e}"

def generate_rule_based_report(fund_datas, macro_data, beijing_time):
    report_parts = [f"# åŸºé‡‘é‡åŒ–è§„åˆ™åˆ†ææŠ¥å‘Š ({beijing_time.strftime('%Y-%m-%d')})\n", macro_data + "\n"]
    if not fund_datas: report_parts.append("### **æ³¨æ„ï¼šæœªèƒ½ä»é›…è™è´¢ç»è·å–ä»»ä½•åŸºé‡‘æ•°æ®ã€‚**")
    else:
        for data in fund_datas:
            score, reasons = 0, []
            if not pd.isna(data['latest_ma']):
                if data['latest_price'] > data['latest_ma']: score += 2; reasons.append("å‡€å€¼åœ¨å‡çº¿ä¹‹ä¸Š")
                else: score -= 2; reasons.append("å‡€å€¼åœ¨å‡çº¿ä¹‹ä¸‹")
            if not pd.isna(data['daily_growth']):
                if data['daily_growth'] > 0: score += 1; reasons.append("å½“æ—¥ä¸Šæ¶¨")
                else: score -= 1; reasons.append("å½“æ—¥ä¸‹è·Œ")
            if score >= 2: conclusion = "å¼ºçƒˆçœ‹å¥½ ğŸš€"
            elif score >= 0: conclusion = "è°¨æ…ä¹è§‚ ğŸ‘"
            elif score > -2: conclusion = "æ³¨æ„é£é™© âš ï¸"
            else: conclusion = "å»ºè®®å‡ä»“ ğŸ“‰"
            report_parts.append(f"### {data['name']} ({data['code']})\n- **é‡åŒ–è¯„åˆ†**: {score}\n- **ç»¼åˆç»“è®º**: {conclusion}\n- **è¯„åˆ†ä¾æ®**: {', '.join(reasons)}\n")
    return "\n".join(report_parts)

def call_gemini_ai(prompt):
    try:
        genai.configure(api_key=os.environ.get("GEMINI_API_KEY"))
        return genai.GenerativeModel("gemini-1.5-flash").generate_content(prompt).text
    except Exception as e: return f"AIæ¨¡å‹è°ƒç”¨å¤±è´¥: {e}"

def generate_ai_based_report(news, sectors, funds_string, macro_data):
    if not funds_string.strip(): return "ç”±äºæœªèƒ½è·å–ä»»ä½•åŸºé‡‘çš„è¯¦ç»†æ•°æ®ï¼ŒAIç­–ç•¥å¤§è„‘æ— æ³•è¿›è¡Œåˆ†æã€‚"
    analysis_prompt = f"""ä½œä¸ºä¸€åé¡¶çº§çš„ä¸­å›½å¸‚åœºå¯¹å†²åŸºé‡‘ç»ç†ï¼Œè¯·ç»“åˆä»¥ä¸‹æ‰€æœ‰ä¿¡æ¯ï¼Œæ’°å†™ä¸€ä»½åŒ…å«å®è§‚ã€ä¸­è§‚ã€å¾®è§‚ä¸‰ä¸ªå±‚æ¬¡çš„æ·±åº¦æŠ•ç ”æŠ¥å‘Š...\n**ç¬¬ä¸€éƒ¨åˆ†ï¼šä¸­å›½å®è§‚ç»æµèƒŒæ™¯ (æ¥æº: AkShare)**\n{macro_data}\n**ç¬¬äºŒéƒ¨åˆ†ï¼šå¸‚åœºæ–°é—»ä¸æƒ…ç»ª**\n{news}\n**ç¬¬ä¸‰éƒ¨åˆ†ï¼šä¸­è§‚è¡Œä¸šä¸æ¿å—è½®åŠ¨**\n{sectors}\n**ç¬¬å››éƒ¨åˆ†ï¼šå¾®è§‚æŒä»“åŸºé‡‘æŠ€æœ¯çŠ¶æ€ (æ¥æº: Yahoo Finance)**\n{funds_string}"""
    draft = call_gemini_ai(analysis_prompt)
    if "AIæ¨¡å‹è°ƒç”¨å¤±è´¥" in draft: return draft
    polish_prompt = f"ä½œä¸ºä¸€åå–„äºç”¨æ•°æ®è®²æ•…äº‹çš„æŠ•èµ„KOLï¼Œè¯·å°†ä»¥ä¸‹è¿™ä»½ä¸“ä¸šçš„æŠ•ç ”æŠ¥å‘Šï¼Œè½¬åŒ–ä¸ºä¸€ç¯‡æ™®é€šæŠ•èµ„è€…éƒ½èƒ½çœ‹æ‡‚çš„ç²¾å½©æ–‡ç« ...\n**ã€åŸå§‹æŠ¥å‘Šã€‘**\n{draft}"
    return call_gemini_ai(polish_prompt)
    
def main():
    if not check_time_interval(): return
    config, beijing_time = load_config(), datetime.datetime.utcnow() + datetime.timedelta(hours=8)
    structured_fund_datas, formatted_fund_strings, macro_data, news_text, sector_text = [], [], "", "", ""

    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:
        future_funds = {executor.submit(get_fund_data_from_yfinance, c, config['historical_days_to_fetch'], config['moving_average_days']): c for c in config['fund_codes']}
        future_macro = executor.submit(get_china_macro_data_from_akshare, config['china_macro_indicators'])
        future_news = {executor.submit(search_news, kw): kw for kw in config['news_keywords']}
        future_sector = executor.submit(get_sector_data)

        for future in concurrent.futures.as_completed(future_funds):
            code = future_funds[future]
            try:
                name, df = future.result()
                structured, formatted = process_fund_data(name, df, code, config['moving_average_days'], config['historical_days_to_display'])
                if structured: structured_fund_datas.append(structured); formatted_fund_strings.append(formatted)
            except Exception as e: print(f"è·å–å¹¶å¤„ç†åŸºé‡‘ {code} æ—¶å‘ç”Ÿé¡¶å±‚é”™è¯¯: {e}")
        
        macro_data = future_macro.result()
        news_text = "\n".join([f.result() for f in concurrent.futures.as_completed(future_news)])
        sector_text = future_sector.result()

    if not os.path.exists('reports'): os.makedirs('reports')
    
    rule_report = generate_rule_based_report(structured_fund_datas, macro_data, beijing_time)
    with open(f"reports/åŸºé‡‘åˆ†ææŠ¥å‘Š-è§„åˆ™ç‰ˆ_{beijing_time.strftime('%Y-%m-%d')}.md", 'w', encoding='utf-8') as f: f.write(rule_report)
    print(f"\nâœ… â€œè§„åˆ™å¤§è„‘â€æŠ¥å‘Šå·²æˆåŠŸä¿å­˜ã€‚")

    ai_report = generate_ai_based_report(news_text, sector_text, "\n".join(formatted_fund_strings), macro_data)
    with open(f"reports/åŸºé‡‘åˆ†ææŠ¥å‘Š-AIç‰ˆ_{beijing_time.strftime('%Y-%m-%d')}.md", 'w', encoding='utf-8') as f: f.write(ai_report)
    print(f"âœ… â€œAIç­–ç•¥å¤§è„‘â€æŠ¥å‘Šå·²æˆåŠŸä¿å­˜ã€‚")

    update_timestamp()

if __name__ == "__main__":
    main()
