import os
import datetime
import time
import json
import concurrent.futures
import google.generativeai as genai
import requests
import numpy as np
import pandas as pd
from bs4 import BeautifulSoup
from duckduckgo_search import DDGS

# --- å…¨å±€è®¾ç½® ---
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Referer': 'http://fund.eastmoney.com/' # å¢åŠ Refererï¼Œæ›´åƒçœŸå®æµè§ˆå™¨
}
TIMESTAMP_FILE = "last_run_timestamp.txt"
MIN_INTERVAL_HOURS = 6
REQUESTS_TIMEOUT = 20

# --- åŠŸèƒ½å‡½æ•° ---

def load_config():
    """ä»config.jsonåŠ è½½é…ç½®"""
    print("æ­£åœ¨åŠ è½½é…ç½®æ–‡ä»¶ config.json...")
    with open('config.json', 'r', encoding='utf-8') as f:
        return json.load(f)

def check_time_interval():
    """æ£€æŸ¥çªå‘äº‹ä»¶è§¦å‘é—´éš”"""
    github_event_name = os.getenv('GITHUB_EVENT_NAME')
    if github_event_name != 'repository_dispatch':
        return True
    if not os.path.exists(TIMESTAMP_FILE):
        return True
    with open(TIMESTAMP_FILE, "r") as f:
        last_run_timestamp = float(f.read())
    current_timestamp = time.time()
    hours_diff = (current_timestamp - last_run_timestamp) / 3600
    if hours_diff < MIN_INTERVAL_HOURS:
        print(f"è·ç¦»ä¸Šæ¬¡æ‰§è¡Œï¼ˆ{hours_diff:.2f}å°æ—¶ï¼‰æœªè¶…è¿‡{MIN_INTERVAL_HOURS}å°æ—¶ï¼Œæœ¬æ¬¡è·³è¿‡ã€‚")
        return False
    return True

def update_timestamp():
    """æ›´æ–°æ—¶é—´æˆ³æ–‡ä»¶"""
    with open(TIMESTAMP_FILE, "w") as f:
        f.write(str(time.time()))

def search_news(keyword):
    """æœç´¢æ–°é—»"""
    print(f"æ­£åœ¨æœç´¢æ–°é—»: {keyword}...")
    try:
        with DDGS() as ddgs:
            results = [f"- [æ ‡é¢˜] {r['title']}\n  [æ‘˜è¦] {r.get('body', 'æ— ')}\n" for r in ddgs.news(keyword, region='cn-zh', safesearch='off', max_results=5)]
            return "\n".join(results)
    except Exception as e:
        return f"æœç´¢å…³é”®è¯ '{keyword}' å¤±è´¥: {e}"

def get_sector_data():
    """çˆ¬å–è¡Œä¸šæ¿å—æ•°æ®"""
    print("æ­£åœ¨çˆ¬å–è¡Œä¸šæ¿å—æ•°æ®...")
    url = "http://quote.eastmoney.com/center/boardlist.html#industry_board"
    try:
        response = requests.get(url, headers=HEADERS, timeout=REQUESTS_TIMEOUT)
        soup = BeautifulSoup(response.text, 'html.parser')
        sectors = []
        for row in soup.select('table#table_wrapper-table tbody tr'):
            cols = row.find_all('td')
            if len(cols) > 5:
                try:
                    name = cols[1].find('a').text.strip()
                    change = float(cols[4].text.strip().replace('%', ''))
                    sectors.append({'name': name, 'change': change})
                except (ValueError, AttributeError): continue
        
        sectors.sort(key=lambda x: x['change'], reverse=True)
        top_rising = sectors[:10]
        top_falling = sectors[-10:]
        
        rising_str = "\n".join([f"  - {s['name']}: {s['change']:.2f}%" for s in top_rising])
        falling_str = "\n".join([f"  - {s['name']}: {s['change']:.2f}%" for s in top_falling])
        return f"**ã€çƒ­é—¨ä¸Šæ¶¨æ¿å—ã€‘**\n{rising_str}\n\n**ã€çƒ­é—¨ä¸‹è·Œæ¿å—ã€‘**\n{falling_str}"
    except Exception as e:
        return f"è¡Œä¸šæ¿å—æ•°æ®çˆ¬å–å¤±è´¥: {e}"

def get_fund_historical_data_and_ma(fund_code, history_days, ma_days):
    """è·å–åŸºé‡‘å†å²å‡€å€¼å¹¶è®¡ç®—ç§»åŠ¨å¹³å‡çº¿"""
    print(f"æ­£åœ¨è·å–åŸºé‡‘ {fund_code} çš„å†å²æ•°æ®å¹¶è®¡ç®—MA{ma_days}...")
    try:
        url = f"http://api.fund.eastmoney.com/f10/lsjz?fundCode={fund_code}&pageIndex=1&pageSize={history_days}"
        response = requests.get(url, headers=HEADERS, timeout=REQUESTS_TIMEOUT)
        data = response.json()['Data']['LSJZList']
        
        df = pd.DataFrame(data)
        df['FSRQ'] = pd.to_datetime(df['FSRQ'])
        df['DWJZ'] = pd.to_numeric(df['DWJZ'])
        df = df.sort_values('FSRQ')
        
        # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
        df[f'MA{ma_days}'] = df['DWJZ'].rolling(window=ma_days).mean()
        
        latest_data = df.iloc[-1]
        fund_name = response.json()['Data']['FundBaseInfo']['JJJC']
        latest_price = latest_data['DWJZ']
        latest_ma = latest_data[f'MA{ma_days}']
        
        # ç”ŸæˆASCIIå›¾è¡¨
        chart = generate_ascii_chart(latest_price, latest_ma, df['DWJZ'].min(), df['DWJZ'].max())
        
        return f"""
### åŸºé‡‘: {fund_name} ({fund_code})
- **æœ€æ–°å‡€å€¼**: {latest_price:.4f}
- **{ma_days}æ—¥å‡çº¿**: {latest_ma:.4f}
- **è¶‹åŠ¿åˆ†æ**: å½“å‰ä»·æ ¼åœ¨ {ma_days}æ—¥å‡çº¿ **{'ä¹‹ä¸Š' if latest_price > latest_ma else 'ä¹‹ä¸‹'}**ï¼Œå¯èƒ½å¤„äºçŸ­æœŸ**{'ä¸Šå‡' if latest_price > latest_ma else 'ä¸‹é™'}**è¶‹åŠ¿ã€‚
- **ä»·æ ¼ä½ç½®å›¾**:
{chart}
"""
    except Exception as e:
        return f"\n### åŸºé‡‘: {fund_code}\n- å†å²æ•°æ®å’Œå‡çº¿è®¡ç®—å¤±è´¥: {e}\n"

def generate_ascii_chart(price, ma, min_val, max_val, width=25):
    """ç”Ÿæˆä¸€ä¸ªç®€å•çš„æ–‡æœ¬å›¾è¡¨æ¥æ˜¾ç¤ºä»·æ ¼å’Œå‡çº¿çš„ä½ç½®"""
    if price is None or ma is None or pd.isna(ma):
        return "  (æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆå›¾è¡¨)"
    
    val_range = max_val - min_val
    if val_range == 0: return "  (æ•°æ®æ³¢åŠ¨ä¸º0)"

    price_pos = int(((price - min_val) / val_range) * (width - 1))
    ma_pos = int(((ma - min_val) / val_range) * (width - 1))
    
    chart_list = ['-'] * width
    min_str = f"[{min_val:.3f}]"
    max_str = f"[{max_val:.3f}]"

    if price_pos == ma_pos:
        chart_list[price_pos] = 'P/M' # Price and MA are at the same spot
    else:
        chart_list[price_pos] = 'P' # Price
        chart_list[ma_pos] = 'M' # Moving Average
        
    return f"  {min_str} {''.join(chart_list)} {max_str}"

def call_gemini_ai(prompt):
    """è°ƒç”¨Gemini AI"""
    print("æ­£åœ¨è°ƒç”¨ Gemini AI è¿›è¡Œæ·±åº¦åˆ†æ...")
    try:
        genai.configure(api_key=os.environ.get("GEMINI_API_KEY"))
        model = genai.GenerativeModel("gemini-1.5-flash")
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"AIæ¨¡å‹è°ƒç”¨å¤±è´¥: {e}"

def main():
    if not check_time_interval():
        return
    
    config = load_config()
    
    print("å¼€å§‹æ‰§è¡Œå¢å¼ºç‰ˆåŸºé‡‘åˆ†æå·¥ä½œæµ...")
    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:
        news_futures = {executor.submit(search_news, kw): kw for kw in config['news_keywords']}
        fund_futures = {executor.submit(get_fund_historical_data_and_ma, code, config['historical_days_to_fetch'], config['moving_average_days']): code for code in config['fund_codes']}
        sector_future = executor.submit(get_sector_data)

        all_news_text = "\n".join([f.result() for f in concurrent.futures.as_completed(news_futures)])
        all_fund_data = "\n".join([f.result() for f in concurrent.futures.as_completed(fund_futures)])
        sector_data_text = sector_future.result()

    # --- æ‰“å°æ±‡æ€»ä¿¡æ¯ ---
    print("\n" + "="*50 + "\n--- æ•°æ®æ±‡æ€» ---\n" + "="*50)
    print(f"\n--- å®è§‚æ–°é—» ---\n{all_news_text}")
    print(f"\n--- è¡Œä¸šæ¿å— ---\n{sector_data_text}")
    print(f"\n--- åŸºé‡‘æŠ€æœ¯åˆ†æ ---\n{all_fund_data}")
    print("\n" + "="*50)

    # --- AIåˆ†æ ---
    analysis_prompt = f"""
ä½œä¸ºä¸€åæ‹¥æœ‰å®šé‡åˆ†æï¼ˆQuantï¼‰å’Œå®è§‚ç»æµåˆ†æåŒé‡èƒŒæ™¯çš„é¡¶çº§æŠ•èµ„ç»„åˆç»ç†ï¼Œè¯·æ ¹æ®ä»¥ä¸‹ä¸‰æ–¹é¢ä¿¡æ¯ï¼Œæ’°å†™ä¸€ä»½ä¸“ä¸šã€æ·±å…¥ä¸”å¯æ‰§è¡Œçš„æŠ•èµ„ç­–ç•¥æŠ¥å‘Šã€‚

**ç¬¬ä¸€éƒ¨åˆ†ï¼šå®è§‚æ–°é—»ä¸å¸‚åœºæƒ…ç»ª (å®šæ€§åˆ†æ)**
{all_news_text}

**ç¬¬äºŒéƒ¨åˆ†ï¼šå¸‚åœºç»“æ„ä¸æ¿å—è½®åŠ¨ (ä¸­è§‚åˆ†æ)**
{sector_data_text}

**ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ ¸å¿ƒæŒä»“æŠ€æœ¯çŠ¶æ€ (å¾®è§‚é‡åŒ–åˆ†æ)**
{all_fund_data}

**ã€ç­–ç•¥æŠ¥å‘Šæ’°å†™æŒ‡ä»¤ã€‘**
1.  **é¡¶å±‚åˆ¤æ–­ (Top-Down Analysis)**: é¦–å…ˆï¼Œç»“åˆã€å®è§‚æ–°é—»ã€‘å’Œã€æ¿å—æ•°æ®ã€‘ï¼Œåˆ¤æ–­å½“å‰å¸‚åœºçš„æ•´ä½“ç¯å¢ƒã€‚æ˜¯é£é™©åå¥½æå‡çš„è¿›æ”»æœŸï¼Œè¿˜æ˜¯é£é™©åŒæ¶ä¸»å¯¼çš„é˜²å®ˆæœŸï¼Ÿå¸‚åœºèµ„é‡‘çš„ä¸»çº¿åœ¨å“ªé‡Œï¼Ÿ
2.  **é‡åŒ–éªŒè¯ (Quantitative Check)**: æ£€è§†ã€æ ¸å¿ƒæŒä»“æŠ€æœ¯çŠ¶æ€ã€‘ã€‚åŸºé‡‘çš„çŸ­æœŸè¶‹åŠ¿ï¼ˆä»·æ ¼ä¸å‡çº¿å…³ç³»ï¼‰æ˜¯å¦ä¸ä½ çš„å®è§‚åˆ¤æ–­ç›¸ç¬¦ï¼Ÿæ˜¯å¦å­˜åœ¨èƒŒç¦»ï¼Ÿï¼ˆä¾‹å¦‚ï¼Œå®è§‚ä¸€ç‰‡å‘å¥½ï¼Œä½†ä½ çš„æŒä»“å´è·Œç ´äº†å‡çº¿ï¼‰ã€‚
3.  **å…·ä½“ç­–ç•¥åˆ¶å®š (Actionable Strategy)**:
    *   **è¿›æ”»ç­–ç•¥**: å¦‚æœåˆ¤æ–­å¸‚åœºå‘å¥½ï¼Œåº”ä¼˜å…ˆåŠ ä»“å“ªäº›â€œå®è§‚é¡ºé£â€ä¸”â€œæŠ€æœ¯å½¢æ€è‰¯å¥½â€ï¼ˆä»·æ ¼åœ¨å‡çº¿ä¹‹ä¸Šï¼‰çš„åŸºé‡‘ï¼Ÿ
    *   **é˜²å®ˆç­–ç•¥**: å¦‚æœåˆ¤æ–­å¸‚åœºæœ‰é£é™©ï¼Œåº”è€ƒè™‘å‡ä»“æˆ–å–å‡ºå“ªäº›â€œå®è§‚é€†é£â€æˆ–â€œæŠ€æœ¯å½¢æ€èµ°åâ€ï¼ˆä»·æ ¼è·Œç ´å‡çº¿ï¼‰çš„åŸºé‡‘ï¼Ÿ
    *   **è§‚æœ›ç­–ç•¥**: å¯¹äºé‚£äº›å®è§‚å’ŒæŠ€æœ¯æŒ‡æ ‡è¡¨ç°çŸ›ç›¾çš„åŸºé‡‘ï¼Œç»™å‡ºè§‚æœ›æˆ–è½»ä»“æ“ä½œçš„å»ºè®®ã€‚
4.  **æ€»ç»“ä¸é£é™©**: ç”¨ç®€æ´çš„è¯­è¨€æ€»ç»“æ ¸å¿ƒæ“ä½œå»ºè®®ï¼Œå¹¶æ˜ç¡®æŒ‡å‡ºè¯¥ç­–ç•¥é¢ä¸´çš„æœ€å¤§é£é™©æ˜¯ä»€ä¹ˆã€‚
"""
    draft_article = call_gemini_ai(analysis_prompt)
    
    # --- AIæ¶¦è‰² ---
    polish_prompt = f"""
ä½œä¸ºä¸€åé¡¶çº§çš„æŠ•èµ„ç¤¾åŒºæ„è§é¢†è¢–ï¼ˆKOLï¼‰ï¼Œè¯·å°†ä»¥ä¸‹è¿™ä»½ç¡¬æ ¸çš„ä¸“ä¸šæŠ•ç ”æŠ¥å‘Šï¼Œè½¬åŒ–ä¸ºä¸€ç¯‡æ™®é€šæŠ•èµ„è€…éƒ½èƒ½çœ‹æ‡‚ã€ä¸”æ„¿æ„çœ‹ä¸‹å»çš„ç²¾å½©æ–‡ç« ã€‚

**ã€åŸå§‹æŠ¥å‘Šã€‘**
{draft_article}

**ã€æ¶¦è‰²è¦æ±‚ã€‘**
1.  **æ ‡é¢˜**: èµ·ä¸€ä¸ªâ€œæŠ“çœ¼çƒâ€çš„æ ‡é¢˜ï¼Œä¾‹å¦‚ï¼šâ€œå¸‚åœºå¤§å˜å¤©ï¼æˆ‘çš„åŸºé‡‘è¯¥è·‘è¿˜æ˜¯è¯¥æŠ„åº•ï¼ŸæŠ€æœ¯æŒ‡æ ‡ç»™å‡ºç­”æ¡ˆï¼â€
2.  **å¼€åœº**: ç”¨ä¸€ä¸ªçƒ­é—¨äº‹ä»¶æˆ–è€…ç”ŸåŠ¨çš„æ¯”å–»å¼€åœºï¼Œç›´æ¥åˆ‡å…¥ä»Šå¤©å¸‚åœºçš„æ ¸å¿ƒçŸ›ç›¾ã€‚
3.  **â€œç¿»è¯‘â€æˆäººè¯**: å°†â€œå®è§‚â€ã€â€œé‡åŒ–â€ã€â€œæŠ€æœ¯å½¢æ€â€ç­‰ä¸“ä¸šæœ¯è¯­ï¼Œç”¨å¤§ç™½è¯è§£é‡Šæ¸…æ¥šã€‚ä¾‹å¦‚ï¼ŒæŠŠâ€œä»·æ ¼åœ¨20æ—¥å‡çº¿ä¹‹ä¸Šâ€è§£é‡Šä¸ºâ€œå®ƒè¸©ç¨³äº†çŸ­æœŸç”Ÿå‘½çº¿ï¼ŒåŠ¿å¤´ä¸é”™â€ã€‚
4.  **å›¾æ–‡å¹¶èŒ‚**: åœ¨æ–‡ç« ä¸­æ°å½“ä½¿ç”¨ Emojiï¼ˆä¾‹å¦‚ âœ…, âŒ, ğŸ“ˆ, ğŸ“‰, ğŸ¤”ï¼‰ï¼Œå¢åŠ é˜…è¯»è¶£å‘³ã€‚
5.  **ç»“æ„æ¸…æ™°**: ä½¿ç”¨æ¸…æ™°çš„å°æ ‡é¢˜ï¼Œå¦‚â€œä»Šå¤©å¸‚åœºå‘ç”Ÿäº†å•¥ï¼Ÿâ€ã€â€œæˆ‘çš„åŸºé‡‘æ€ä¹ˆæ ·äº†ï¼Ÿâ€ã€â€œæ‰€ä»¥ï¼Œåˆ°åº•è¯¥å’‹åŠï¼Ÿâ€ã€‚
6.  **ç»“å°¾**: å¼ºåŠ¿æ€»ç»“è§‚ç‚¹ï¼Œå¹¶åŠ ä¸Šäº’åŠ¨æ€§çš„è¯è¯­ï¼Œæœ€åé™„ä¸Šå…è´£å£°æ˜ã€‚
"""
    final_article = call_gemini_ai(polish_prompt)

    # --- ä¿å­˜æ–‡ä»¶ ---
    print("\n--- æœ€ç»ˆç”Ÿæˆçš„ç¤¾åŒºæ–‡ç«  ---")
    print(final_article)
    if not os.path.exists('reports'): os.makedirs('reports')
    beijing_time = datetime.datetime.utcnow() + datetime.timedelta(hours=8)
    file_name = f"reports/åŸºé‡‘åˆ†ææŠ¥å‘Š_{beijing_time.strftime('%Y-%m-%d_%H-%M')}.md"
    with open(file_name, 'w', encoding='utf-8') as f: f.write(final_article)
    print(f"\næŠ¥å‘Šå·²æˆåŠŸä¿å­˜ä¸º: {file_name}")
    
    update_timestamp()

if __name__ == "__main__":
    main()
